<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>thunderlab.dataloader API documentation</title>
<meta name="description" content="Load time-series data from files â€¦">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>thunderlab.dataloader</code></h1>
</header>
<section id="section-intro">
<p>Load time-series data from files.</p>
<pre><code>data, rate, unit, amax = load_data('data/file.wav')
</code></pre>
<p>The function <code>data_loader()</code> loads the whole time-series from the file
as a numpy array of floats.
First dimension is frames, second is
channels. In contrast to the <code>audioio.load_audio()</code> function, the
values of the data array are not restricted between -1 and 1. They can
assume any value wihin the range <code>-amax</code> to <code>+amax</code> with the returned
<code>unit</code>.</p>
<pre><code>data = DataLoader('data/file.wav', 60.0)
</code></pre>
<p>or</p>
<pre><code>with DataLoader('data/file.wav', 60.0) as data:
</code></pre>
<p>Create an <code><a title="thunderlab.dataloader.DataLoader" href="#thunderlab.dataloader.DataLoader">DataLoader</a></code> object that loads chuncks of 60 seconds long data
on demand. <code>data</code> can be used like a read-only numpy array of floats.</p>
<h2 id="supported-file-formats">Supported file formats</h2>
<ul>
<li>python pickle files</li>
<li>numpy .npz files</li>
<li>matlab .mat files</li>
<li>audio files via <a href="https://github.com/bendalab/audioio"><code>audioio</code></a> package</li>
<li>LabView .scandat files</li>
<li>raw files</li>
<li>relacs files (<a href="https://www.relacs.net">https://www.relacs.net</a>)</li>
<li>fishgrid files (<a href="https://github.com/bendalab/fishgrid">https://github.com/bendalab/fishgrid</a>)</li>
</ul>
<h2 id="metadata">Metadata</h2>
<p>Many file formats allow to store metadata that further describe the
stored time series data. We handle them as nested dictionary of key-value
pairs. Load them with the <code><a title="thunderlab.dataloader.metadata" href="#thunderlab.dataloader.metadata">metadata()</a></code> function:</p>
<pre><code>metadata = metadata('data/file.mat')
</code></pre>
<h2 id="markers">Markers</h2>
<p>Some file formats also allow to store markers that mark specific
positions in the time series data. Load marker positions and spans (in
the 2-D array <code>locs</code>) and label and text strings (in the 2-D array
<code>labels</code>) with the <code><a title="thunderlab.dataloader.markers" href="#thunderlab.dataloader.markers">markers()</a></code> function:</p>
<pre><code>locs, labels = markers('data.wav')
</code></pre>
<h2 id="aditional-format-specific-functions">Aditional, format specific functions</h2>
<ul>
<li><code><a title="thunderlab.dataloader.extract_container_metadata" href="#thunderlab.dataloader.extract_container_metadata">extract_container_metadata()</a></code>: extract metadata from dictionary loaded from a container file.</li>
<li><code><a title="thunderlab.dataloader.relacs_samplerate_unit" href="#thunderlab.dataloader.relacs_samplerate_unit">relacs_samplerate_unit()</a></code>: retrieve sampling rate and unit from a relacs stimuli.dat file.</li>
<li><code><a title="thunderlab.dataloader.relacs_header" href="#thunderlab.dataloader.relacs_header">relacs_header()</a></code>: read key-value pairs from relacs *.dat file headers.</li>
<li><code><a title="thunderlab.dataloader.fishgrid_grids" href="#thunderlab.dataloader.fishgrid_grids">fishgrid_grids()</a></code>: retrieve grid sizes from a fishgrid.cfg file.</li>
<li><code><a title="thunderlab.dataloader.fishgrid_spacings" href="#thunderlab.dataloader.fishgrid_spacings">fishgrid_spacings()</a></code>: spacing between grid electrodes.</li>
</ul>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="thunderlab.dataloader.data_loader_funcs"><code class="name">var <span class="ident">data_loader_funcs</span></code></dt>
<dd>
<div class="desc"><p>List of implemented load functions.</p>
<p>Each element of the list is a tuple with the data format's name, its
check and its load function.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="thunderlab.dataloader.relacs_samplerate_unit"><code class="name flex">
<span>def <span class="ident">relacs_samplerate_unit</span></span>(<span>filepath, channel=0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def relacs_samplerate_unit(filepath, channel=0):
    &#34;&#34;&#34;Retrieve sampling rate and unit from a relacs stimuli.dat file.

    Parameters
    ----------
    filepath: str or Path
        Path to a relacs data directory, or a file in a relacs data directory.
    channel: int
        Channel (trace) number, if `filepath` does not specify a
        trace-*.raw file.

    Returns
    -------
    samplerate: float
        Sampling rate in Hertz
    unit: str
        Unit of the trace, can be empty if not found

    Raises
    ------
    IOError/FileNotFoundError:
        If the stimuli.dat file does not exist.
    ValueError:
        stimuli.dat file does not contain sampling rate.
    &#34;&#34;&#34;
    trace = channel + 1
    relacs_dir = Path(filepath)
    # check for relacs data directory:
    if not relacs_dir.is_dir():
        bn = relacs_dir.stem.lower()
        ext = relacs_dir.suffix.lower()
        relacs_dir = relacs_dir.parent
        if len(bn) &gt; 6 and bn[:6] == &#39;trace-&#39;:
            trace = int(bn[6:])

    # retreive sampling rate and unit from stimuli.dat file:
    samplerate = None
    sampleinterval = None
    unit = &#34;&#34;

    # load stimuli.dat file:
    lines = []
    stimuli_file = relacs_dir / &#39;stimuli.dat.gz&#39;
    if stimuli_file.is_file():
        with gzip.open(stimuli_file, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                line = line.strip()
                if len(line) == 0 or line[0] != &#39;#&#39;:
                    break
                lines.append(line)
    else:
        stimuli_file = relacs_dir / &#39;stimuli.dat&#39;
        with open(stimuli_file, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                line = line.strip()
                if len(line) == 0 or line[0] != &#39;#&#39;:
                    break
                lines.append(line)
    # extract unit and sampling rate:        
    for line in lines:
        if f&#39;unit{trace}&#39; in line:
            unit = line.split(&#39;:&#39;)[1].strip()
        if f&#39;sampling rate{trace}&#39; in line:
            value = line.split(&#39;:&#39;)[1].strip()
            samplerate = float(value.replace(&#39;Hz&#39;,&#39;&#39;))
        elif f&#39;sample interval{trace}&#39; in line:
            value = line.split(&#39;:&#39;)[1].strip()
            sampleinterval = float(value.replace(&#39;ms&#39;,&#39;&#39;))

    if samplerate is not None:
        return samplerate, unit
    if sampleinterval is not None:
        return 1000/sampleinterval, unit
    raise ValueError(f&#39;could not retrieve sampling rate from {stimuli_file}&#39;)</code></pre>
</details>
<div class="desc"><p>Retrieve sampling rate and unit from a relacs stimuli.dat file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to a relacs data directory, or a file in a relacs data directory.</dd>
<dt><strong><code>channel</code></strong> :&ensp;<code>int</code></dt>
<dd>Channel (trace) number, if <code>filepath</code> does not specify a
trace-*.raw file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>samplerate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate in Hertz</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the trace, can be empty if not found</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>IOError/FileNotFoundError:</code></dt>
<dd>If the stimuli.dat file does not exist.</dd>
</dl>
<h2 id="valueerror">Valueerror</h2>
<p>stimuli.dat file does not contain sampling rate.</p></div>
</dd>
<dt id="thunderlab.dataloader.relacs_header"><code class="name flex">
<span>def <span class="ident">relacs_header</span></span>(<span>filepath,<br>store_empty=False,<br>first_only=False,<br>lower_keys=False,<br>flat=False,<br>add_sections=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def relacs_header(filepath, store_empty=False, first_only=False,
                  lower_keys=False, flat=False,
                  add_sections=False):
    &#34;&#34;&#34;Read key-value pairs from a relacs *.dat file header.

    Parameters
    ----------
    filepath: str or Path
        A relacs *.dat file, can be also a zipped .gz file.
    store_empty: bool
        If `False` do not add meta data with empty values.
    first_only: bool
        If `False` only store the first element of a list.
    lower_keys: bool
        Make all keys lower case.
    flat: bool
        Do not make a nested dictionary.
        Use this option also to read in very old relacs metadata with
        ragged left alignment.
    add_sections: bool
        If `True`, prepend keys with sections names separated by
        &#39;.&#39; to make them unique.

    Returns
    -------
    data: dict
        Nested dictionary with key-value pairs of the file header.
        
    Raises
    ------
    IOError/FileNotFoundError:
        If `filepath` cannot be opened.
    &#34;&#34;&#34;
    filepath = Path(filepath)
    # read in header from file:
    lines = []
    gzfilepath = filepath.with_suffix(filepath.suffix + &#39;.gz&#39;)
    if gzfilepath.is_file():
        with gzip.open(gzfilepath, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                line = line.strip()
                if len(line) == 0 or line[0] != &#39;#&#39;:
                    break
                lines.append(line)
    else:
        with open(filepath, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                line = line.strip()
                if len(line) == 0 or line[0] != &#39;#&#39;:
                    break
                lines.append(line)
    # parse:
    data = {}
    cdatas = [data]
    sections = [&#39;&#39;]
    ident_offs = None
    ident = None
    for line in lines:
        words = line.split(&#39;:&#39;)
        value = &#39;:&#39;.join(words[1:]).strip() if len(words) &gt; 1 else &#39;&#39;
        if len(words) &gt;= 1:
            key = words[0].strip(&#39;#&#39;)
            # get section level:
            level = 0
            if not flat or len(value) == 0:
                nident = len(key) - len(key.lstrip())
                if ident_offs is None:
                    ident_offs = nident
                elif ident is None:
                    if nident &gt; ident_offs:
                        ident = nident - ident_offs
                        level = 1
                else:
                    level = (nident - ident_offs)//ident
                # close sections:
                if not flat:
                    while len(cdatas) &gt; level + 1:
                        cdatas[-1][sections.pop()] = cdatas.pop()
                else:
                    while len(sections) &gt; level + 1:
                        sections.pop()
            # key:
            key = key.strip().strip(&#39;&#34;&#39;)
            if lower_keys:
                key = key.lower()
            skey = key
            if add_sections:
                key = &#39;.&#39;.join(sections[1:] + [key])
            if len(value) == 0:
                # new sub-section:
                if flat:
                    if store_empty:
                        cdatas[-1][key] = None
                else:
                    cdatas.append({})
                sections.append(skey)
            else:
                # key-value pair:
                value = value.strip(&#39;&#34;&#39;)
                if len(value) &gt; 0 or value != &#39;-&#39; or store_empty:
                    if len(value) &gt; 0 and value[0] == &#39;[&#39; and value[-1] == &#39;]&#39;:
                        value = [v.strip() for v in value.lstrip(&#39;[&#39;).rstrip(&#39;]&#39;).split(&#39;,&#39;)]
                        if first_only:
                            value = value[0]
                    cdatas[-1][key] = value
    while len(cdatas) &gt; 1:
        cdatas[-1][sections.pop()] = cdatas.pop()
    return data</code></pre>
</details>
<div class="desc"><p>Read key-value pairs from a relacs *.dat file header.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A relacs *.dat file, can be also a zipped .gz file.</dd>
<dt><strong><code>store_empty</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>False</code> do not add meta data with empty values.</dd>
<dt><strong><code>first_only</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>False</code> only store the first element of a list.</dd>
<dt><strong><code>lower_keys</code></strong> :&ensp;<code>bool</code></dt>
<dd>Make all keys lower case.</dd>
<dt><strong><code>flat</code></strong> :&ensp;<code>bool</code></dt>
<dd>Do not make a nested dictionary.
Use this option also to read in very old relacs metadata with
ragged left alignment.</dd>
<dt><strong><code>add_sections</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, prepend keys with sections names separated by
'.' to make them unique.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>Nested dictionary with key-value pairs of the file header.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>IOError/FileNotFoundError:</code></dt>
<dd>If <code>filepath</code> cannot be opened.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.check_relacs"><code class="name flex">
<span>def <span class="ident">check_relacs</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_relacs(filepath):
    &#34;&#34;&#34;Check for valid relacs file.

    Parameters
    ----------
    filepath: str or Path
        Path to a relacs data directory, or a file in a relacs data directory.

    Returns
    -------
    is_relacs: boolean
      `True` if `filepath` is a valid relacs directory or is a file therein.
    &#34;&#34;&#34;
    # relacs data directory:
    relacs_dir = Path(filepath)
    if not relacs_dir.is_dir():
        relacs_dir = relacs_dir.parent
    # check for a valid relacs data directory:
    has_stimuli = False
    has_trace = False
    for fname in [&#39;stimuli.dat&#39;, &#39;stimuli.dat.gz&#39;]:
        if (relacs_dir / fname).is_file():
            has_stimuli = True
            break
    for fname in [&#39;trace-1.raw&#39;, &#39;trace-1.raw.gz&#39;]:
        if (relacs_dir / fname).is_file():
            has_trace = True
            break
    return has_stimuli and has_trace</code></pre>
</details>
<div class="desc"><p>Check for valid relacs file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to a relacs data directory, or a file in a relacs data directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>is_relacs</code></strong> :&ensp;<code>boolean</code></dt>
<dd>&nbsp;</dd>
</dl>
<p><code>True</code> if <code>filepath</code> is a valid relacs directory or is a file therein.</p></div>
</dd>
<dt id="thunderlab.dataloader.relacs_trace_files"><code class="name flex">
<span>def <span class="ident">relacs_trace_files</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def relacs_trace_files(filepath):
    &#34;&#34;&#34;Expand file path for relacs data to appropriate trace*.raw file names.

    Parameters
    ----------
    filepath: str or Path
        Path to a relacs data directory, or a file in a relacs data directory.
        
    Returns
    -------
    trace_filepaths: list of Path
        List of relacs trace*.raw files.
    &#34;&#34;&#34;
    relacs_dir = Path(filepath)
    if not relacs_dir.is_dir():
        relacs_dir = relacs_dir.parent
    trace_filepaths = []
    for k in range(10000):
        trace_file = relacs_dir / f&#39;trace-{k+1}.raw&#39;
        gz_trace_file = relacs_dir / f&#39;trace-{k+1}.raw.gz&#39;
        if trace_file.is_file():
            trace_filepaths.append(trace_file)
        elif gz_trace_file.is_file():
            trace_filepaths.append(gz_trace_file)
        else:
            break
    return trace_filepaths</code></pre>
</details>
<div class="desc"><p>Expand file path for relacs data to appropriate trace*.raw file names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to a relacs data directory, or a file in a relacs data directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>trace_filepaths</code></strong> :&ensp;<code>list</code> of <code>Path</code></dt>
<dd>List of relacs trace*.raw files.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.load_relacs"><code class="name flex">
<span>def <span class="ident">load_relacs</span></span>(<span>filepath, amax=1.0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_relacs(filepath, amax=1.0):
    &#34;&#34;&#34;Load traces that have been recorded with relacs (https://github.com/relacs/relacs).

    Parameters
    ----------
    filepath: str of Path
        Path to a relacs data directory, or a file in a relacs data directory.
    amax: float
        The amplitude range of the data.

    Returns
    -------
    data: 2-D array
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz
    unit: str
        Unit of the data
    amax: float
        Maximum amplitude of data range.

    Raises
    ------
    FileNotFoundError:
        Invalid or non existing relacs files.
    ValueError:
        - Invalid name for relacs trace-*.raw file.
        - Sampling rates of traces differ.
        - Unit of traces differ.
    &#34;&#34;&#34;
    trace_filepaths = relacs_trace_files(filepath)
    if len(trace_filepaths) == 0:
        raise FileNotFoundError(f&#39;no relacs files found&#39;)
    # load trace*.raw files:
    nchannels = len(trace_filepaths)
    data = None
    nrows = 0
    rate = None
    unit = &#39;&#39;
    for c, path in enumerate(sorted(trace_filepaths)):
        if path.suffix == &#39;.gz&#39;:
            with gzip.open(path, &#39;rb&#39;) as sf:
                x = np.frombuffer(sf.read(), dtype=np.float32)
        else:
            x = np.fromfile(path, np.float32)
        if data is None:
            nrows = len(x)
            data = np.zeros((nrows, nchannels))
        n = min(len(x), nrows)
        data[:n,c] = x[:n]
        # retrieve sampling rate and unit:
        crate, us = relacs_samplerate_unit(path, c)
        if rate is None:
            rate = crate
        elif crate != rate:
            raise ValueError(&#39;sampling rates of traces differ&#39;)
        if len(unit) == 0:
            unit = us
        elif us != unit:
            raise ValueError(&#39;unit of traces differ&#39;)
    return data, rate, unit, amax</code></pre>
</details>
<div class="desc"><p>Load traces that have been recorded with relacs (<a href="https://github.com/relacs/relacs">https://github.com/relacs/relacs</a>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> of <code>Path</code></dt>
<dd>Path to a relacs data directory, or a file in a relacs data directory.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>The amplitude range of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="filenotfounderror">Filenotfounderror</h2>
<p>Invalid or non existing relacs files.</p>
<h2 id="valueerror">Valueerror</h2>
<ul>
<li>Invalid name for relacs trace-*.raw file.</li>
<li>Sampling rates of traces differ.</li>
<li>Unit of traces differ.</li>
</ul></div>
</dd>
<dt id="thunderlab.dataloader.metadata_relacs"><code class="name flex">
<span>def <span class="ident">metadata_relacs</span></span>(<span>filepath,<br>store_empty=False,<br>first_only=False,<br>lower_keys=False,<br>flat=False,<br>add_sections=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def metadata_relacs(filepath, store_empty=False, first_only=False,
                    lower_keys=False, flat=False, add_sections=False):
    &#34;&#34;&#34; Read meta-data of a relacs data set.

    Parameters
    ----------
    filepath: str or Path
        A relacs data directory or a file therein.
    store_empty: bool
        If `False` do not add meta data with empty values.
    first_only: bool
        If `False` only store the first element of a list.
    lower_keys: bool
        Make all keys lower case.
    flat: bool
        Do not make a nested dictionary.
        Use this option also to read in very old relacs metadata with
        ragged left alignment.
    add_sections: bool
        If `True`, prepend keys with sections names separated by
        &#39;.&#39; to make them unique.

    Returns
    -------
    data: nested dict
        Nested dictionary with key-value pairs of the meta data.
    &#34;&#34;&#34;
    relacs_dir = Path(filepath)
    if not relacs_dir.is_dir():
        relacs_dir = relacs_dir.parent
    info_path = relacs_dir / &#39;info.dat&#39;
    if not info_path.is_file():
        return dict()
    data = relacs_header(info_path, store_empty, first_only,
                         lower_keys, flat, add_sections)
    return data</code></pre>
</details>
<div class="desc"><p>Read meta-data of a relacs data set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A relacs data directory or a file therein.</dd>
<dt><strong><code>store_empty</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>False</code> do not add meta data with empty values.</dd>
<dt><strong><code>first_only</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>False</code> only store the first element of a list.</dd>
<dt><strong><code>lower_keys</code></strong> :&ensp;<code>bool</code></dt>
<dd>Make all keys lower case.</dd>
<dt><strong><code>flat</code></strong> :&ensp;<code>bool</code></dt>
<dd>Do not make a nested dictionary.
Use this option also to read in very old relacs metadata with
ragged left alignment.</dd>
<dt><strong><code>add_sections</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, prepend keys with sections names separated by
'.' to make them unique.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>nested dict</code></dt>
<dd>Nested dictionary with key-value pairs of the meta data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.fishgrid_spacings"><code class="name flex">
<span>def <span class="ident">fishgrid_spacings</span></span>(<span>metadata, unit='m')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fishgrid_spacings(metadata, unit=&#39;m&#39;):
    &#34;&#34;&#34;Spacing between grid electrodes.

    Parameters
    ----------
    metadata: dict
        Fishgrid metadata obtained from `metadata_fishgrid()`.
    unit: str
        Unit in which to return the spacings.

    Returns
    -------
    grid_dist: list of tuple of float
        For each grid the distances between rows and columns in `unit`.
    &#34;&#34;&#34;
    grids_dist = []
    for k in range(4):
        row_dist = get_number(metadata, unit, f&#39;RowDistance{k+1}&#39;, default=0)
        col_dist = get_number(metadata, unit, f&#39;ColumnDistance{k+1}&#39;, default=0)
        rows = get_int(metadata, f&#39;Rows{k+1}&#39;, default=0)
        cols = get_int(metadata, f&#39;Columns{k+1}&#39;, default=0)
        if get_bool(metadata, f&#39;Used{k+1}&#39;, default=False) or \
           cols &gt; 0 and rows &gt; 0:
            grids_dist.append((row_dist, col_dist))
    return grids_dist</code></pre>
</details>
<div class="desc"><p>Spacing between grid electrodes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Fishgrid metadata obtained from <code><a title="thunderlab.dataloader.metadata_fishgrid" href="#thunderlab.dataloader.metadata_fishgrid">metadata_fishgrid()</a></code>.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit in which to return the spacings.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>grid_dist</code></strong> :&ensp;<code>list</code> of <code>tuple</code> of <code>float</code></dt>
<dd>For each grid the distances between rows and columns in <code>unit</code>.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.fishgrid_grids"><code class="name flex">
<span>def <span class="ident">fishgrid_grids</span></span>(<span>metadata)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fishgrid_grids(metadata):
    &#34;&#34;&#34;Retrieve grid sizes from a fishgrid.cfg file.

    Parameters
    ----------
    metadata: dict
        Fishgrid metadata obtained from `metadata_fishgrid()`.

    Returns
    -------
    grids: list of tuple of int
        For each grid the number of rows and columns.
    &#34;&#34;&#34;
    grids = []
    for k in range(4):
        rows = get_int(metadata, f&#39;Rows{k+1}&#39;, default=0)
        cols = get_int(metadata, f&#39;Columns{k+1}&#39;, default=0)
        if get_bool(metadata, f&#39;Used{k+1}&#39;, default=False) or \
           cols &gt; 0 and rows &gt; 0:
            grids.append((rows, cols))
    return grids</code></pre>
</details>
<div class="desc"><p>Retrieve grid sizes from a fishgrid.cfg file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Fishgrid metadata obtained from <code><a title="thunderlab.dataloader.metadata_fishgrid" href="#thunderlab.dataloader.metadata_fishgrid">metadata_fishgrid()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>grids</code></strong> :&ensp;<code>list</code> of <code>tuple</code> of <code>int</code></dt>
<dd>For each grid the number of rows and columns.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.check_fishgrid"><code class="name flex">
<span>def <span class="ident">check_fishgrid</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_fishgrid(filepath):
    &#34;&#34;&#34;Check for valid fishgrid file (https://github.com/bendalab/fishgrid).

    Parameters
    ----------
    filepath: str or Path
        Path to a fishgrid data directory or a file in a fishgrid
        data directory.

    Returns
    -------
    is_fishgrid: bool
        `True` if `filepath` is a valid fishgrid data directory or
        a file therein.
    &#34;&#34;&#34;
    # fishgrid data directory:
    fishgrid_dir = Path(filepath)
    if not fishgrid_dir.is_dir():
        fishgrid_dir = fishgrid_dir.parent
    # check for a valid fishgrid data directory:
    return ((fishgrid_dir / &#39;fishgrid.cfg&#39;).is_file() and
            ((fishgrid_dir / &#39;traces-grid1.raw&#39;).is_file() or
             (fishgrid_dir / &#39;traces.raw&#39;).is_file()))</code></pre>
</details>
<div class="desc"><p>Check for valid fishgrid file (<a href="https://github.com/bendalab/fishgrid">https://github.com/bendalab/fishgrid</a>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to a fishgrid data directory or a file in a fishgrid
data directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>is_fishgrid</code></strong> :&ensp;<code>bool</code></dt>
<dd><code>True</code> if <code>filepath</code> is a valid fishgrid data directory or
a file therein.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.fishgrid_trace_files"><code class="name flex">
<span>def <span class="ident">fishgrid_trace_files</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fishgrid_trace_files(filepath):
    &#34;&#34;&#34;Expand file paths for fishgrid data to appropriate traces*.raw file names.

    Parameters
    ----------
    filepath: str or Path
        Path to a fishgrid data directory, or a file therein.
        
    Returns
    -------
    trace_filepaths: list of Path
        List of fishgrid traces*.raw files.
    &#34;&#34;&#34;
    fishgrid_dir = Path(filepath)
    if not fishgrid_dir.is_dir():
        fishgrid_dir = fishgrid_dir.parent
    # find grids:
    trace_filepaths = []
    for k in range(10000):
        trace_file = fishgrid_dir / f&#39;traces-grid{k+1}.raw&#39;
        gz_trace_file = fishgrid_dir / f&#39;traces-grid{k+1}.raw.gz&#39;
        if trace_file.is_file():
            trace_filepaths.append(trace_file)
        elif gz_trace_file.is_file():
            trace_filepaths.append(gz_trace_file)
        else:
            break
    if len(trace_filepaths) == 0:
        trace_file = fishgrid_dir / f&#39;traces.raw&#39;
        gz_trace_file = fishgrid_dir / f&#39;traces.raw.gz&#39;
        if trace_file.is_file():
            trace_filepaths.append(trace_file)
        elif gz_trace_file.is_file():
            trace_filepaths.append(gz_trace_file)
    return trace_filepaths</code></pre>
</details>
<div class="desc"><p>Expand file paths for fishgrid data to appropriate traces*.raw file names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to a fishgrid data directory, or a file therein.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>trace_filepaths</code></strong> :&ensp;<code>list</code> of <code>Path</code></dt>
<dd>List of fishgrid traces*.raw files.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.load_fishgrid"><code class="name flex">
<span>def <span class="ident">load_fishgrid</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_fishgrid(filepath):
    &#34;&#34;&#34;Load traces that have been recorded with fishgrid (https://github.com/bendalab/fishgrid).

    Parameters
    ----------
    filepath: str
        Path to a fishgrid data directory, or a file therein.

    Returns
    -------
    data: 2-D array
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data.
    amax: float
        Maximum amplitude of data range.

    Raises
    ------
    FileNotFoundError:
        Invalid or non existing fishgrid files.
    &#34;&#34;&#34;
    trace_filepaths = fishgrid_trace_files(filepath)
    if len(trace_filepaths) == 0:
        raise FileNotFoundError(f&#39;no fishgrid files found&#39;)
    md = metadata_fishgrid(filepath)
    grids = fishgrid_grids(md)
    grid_sizes = [r*c for r, c in grids]
                
    # load traces-grid*.raw files:
    grid_channels = []
    nchannels = 0
    for g, path in enumerate(trace_filepaths):
        grid_channels.append(grid_sizes[g])
        nchannels += grid_sizes[g]
    data = None
    nrows = 0
    c = 0
    rate = get_number(md, &#39;Hz&#39;, &#39;AISampleRate&#39;)
    for path, channels in zip(trace_filepaths, grid_channels):
        if path.suffix == &#39;.gz&#39;:
            with gzip.open(path, &#39;rb&#39;) as sf:
                x = np.frombuffer(sf.read(), dtype=np.float32)
        else:
            x = np.fromfile(path, np.float32).reshape((-1, channels))
        if data is None:
            nrows = len(x)
            data = np.zeros((nrows, nchannels))
        n = min(len(x), nrows)
        data[:n, c:c + channels] = x[:n, :]
        c += channels
    amax, unit = get_number_unit(md, &#39;AIMaxVolt&#39;)
    return data, rate, unit, amax</code></pre>
</details>
<div class="desc"><p>Load traces that have been recorded with fishgrid (<a href="https://github.com/bendalab/fishgrid">https://github.com/bendalab/fishgrid</a>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to a fishgrid data directory, or a file therein.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="filenotfounderror">Filenotfounderror</h2>
<p>Invalid or non existing fishgrid files.</p></div>
</dd>
<dt id="thunderlab.dataloader.metadata_fishgrid"><code class="name flex">
<span>def <span class="ident">metadata_fishgrid</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def metadata_fishgrid(filepath):
    &#34;&#34;&#34; Read meta-data of a fishgrid data set.

    Parameters
    ----------
    filepath: str or Path
        A fishgrid data directory or a file therein.

    Returns
    -------
    data: nested dict
        Nested dictionary with key-value pairs of the meta data.
    &#34;&#34;&#34;
    fishgrid_dir = Path(filepath)
    if not fishgrid_dir.is_dir():
        fishgrid_dir = fishgrid_dir.parent
    config_path = fishgrid_dir / &#39;fishgrid.cfg&#39;
    gz_config_path = fishgrid_dir / &#39;fishgrid.cfg.gz&#39;
    # read in header from file:
    lines = []
    if gz_config_path.is_file():
        with gzip.open(gz_config_path, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                lines.append(line)
    elif config_path.is_file():
        with open(config_path, &#39;r&#39;, encoding=&#39;latin-1&#39;) as sf:
            for line in sf:
                lines.append(line)
    else:
        return {}
    # parse:
    data = {}
    cdatas = [data]
    ident_offs = None
    ident = None
    old_style = False
    grid_n = False
    for line in lines:
        if len(line.strip()) == 0:
            continue
        if line[0] == &#39;*&#39;:
            key = line[1:].strip()
            data[key] = {}
            cdatas = [data, data[key]]
        elif &#39;----&#39; in line:
            old_style = True
            key = line.strip().strip(&#39; -&#39;).replace(&#39;&amp;&#39;, &#39;&#39;)
            if key.upper() == &#39;SETUP&#39;:
                key = &#39;Grid 1&#39;
            grid_n = False
            if key[:4].lower() == &#39;grid&#39;:
                grid_n = key[5]
            cdatas = cdatas[:2]
            cdatas[1][key] = {}
            cdatas.append(cdatas[1][key])
        else:
            words = line.split(&#39;:&#39;)
            key = words[0].strip().strip(&#39;&#34;&#39;)
            value = None
            if len(words) &gt; 1 and (len(words[1].strip()) &gt; 0 or old_style):
                value = &#39;:&#39;.join(words[1:]).strip().strip(&#39;&#34;&#39;)
            if old_style:
                if value is None:
                    cdatas = cdatas[:3]
                    cdatas[2][key] = {}
                    cdatas.append(cdatas[2][key])            
                else:
                    if grid_n and key[-1] != grid_n:
                        key = key + grid_n
                    cdatas[-1][key] = value
            else:
                # get section level:
                level = 0
                nident = len(line) - len(line.lstrip())
                if ident_offs is None:
                    ident_offs = nident
                elif ident is None:
                    if nident &gt; ident_offs:
                        ident = nident - ident_offs
                        level = 1
                else:
                    level = (nident - ident_offs)//ident
                # close sections:
                cdatas = cdatas[:2 + level]
                if value is None:
                    # new section:
                    cdatas[-1][key] = {}
                    cdatas.append(cdatas[-1][key])
                else:
                    # key-value pair:
                    cdatas[-1][key] = value.replace(r&#39;\n&#39;, &#39;\n&#39;)
    # remove unused grids:
    fgm = data.get(&#39;FishGrid&#39;, {})
    for i in range(4):
        gs = f&#39;Grid {i+1}&#39;
        if gs in fgm:
            gm = fgm[gs]
            us = f&#39;Used{i+1}&#39;
            if us in gm and gm[us].upper() == &#39;FALSE&#39;:
                del fgm[gs]
    return data</code></pre>
</details>
<div class="desc"><p>Read meta-data of a fishgrid data set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A fishgrid data directory or a file therein.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>nested dict</code></dt>
<dd>Nested dictionary with key-value pairs of the meta data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.markers_fishgrid"><code class="name flex">
<span>def <span class="ident">markers_fishgrid</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def markers_fishgrid(filepath):
    &#34;&#34;&#34; Read markers of a fishgrid data set.

    Parameters
    ----------
    filepath: str or Path
        A fishgrid data directory or a file therein.

    Returns
    -------
    locs: 2-D array of ints
        Marker positions (first column) and spans (second column)
        for each marker (rows).
    labels: 2-D array of string objects
        Labels (first column) and texts (second column)
        for each marker (rows).
    &#34;&#34;&#34;
    def add_marker():
        if &#39;index1&#39; in marker:
            index1 = int(marker[&#39;index1&#39;])//nchannels
        else:
            index1 = int(marker[&#39;index&#39;])//nchannels
        span1 = int(marker.get(&#39;span1&#39;, 0))//nchannels
        locs.append([index1, span1])
        ls = marker.get(&#39;label&#39;, &#39;M&#39;)
        cs = marker.get(&#39;comment&#39;, &#39;&#39;)
        labels.append([ls, cs])
        
    fishgrid_dir = Path(filepath)
    if not fishgrid_dir.is_dir():
        fishgrid_dir = fishgrid_dir.parent
    path = fishgrid_dir / &#39;timestamps.dat&#39;
    if not path.is_file():
        return np.zeros((0, 2), dtype=int), np.zeros((0, 2), dtype=object)
    # get number of channels:
    md = metadata_fishgrid(path.with_name(&#39;fishgrid.cfg&#39;))
    grids = fishgrid_grids(md)
    nchannels = np.prod(grids[0])
    # read timestamps:
    locs = []
    labels = []
    marker = {}
    with open(path, &#39;r&#39;) as sf:
        for line in sf:
            if len(line.strip()) == 0:
                add_marker()
                marker = {}
            else:
                words = line.split(&#39;:&#39;)
                if len(words) &gt; 1:
                    v = words[1].strip()
                    v = v.strip(&#39;&#34;&#39;)
                    marker[words[0].strip().lower()] = v
    if len(marker) &gt; 0:
        add_marker()
    if len(locs) &gt; 2:
        return np.array(locs[1:-1]), np.array(labels[1:-1])
    else:
        return np.zeros((0, 2), dtype=int), np.zeros((0, 2), dtype=object)</code></pre>
</details>
<div class="desc"><p>Read markers of a fishgrid data set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A fishgrid data directory or a file therein.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locs</code></strong> :&ensp;<code>2-D array</code> of <code>ints</code></dt>
<dd>Marker positions (first column) and spans (second column)
for each marker (rows).</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>2-D array</code> of <code>string objects</code></dt>
<dd>Labels (first column) and texts (second column)
for each marker (rows).</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.check_container"><code class="name flex">
<span>def <span class="ident">check_container</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_container(filepath):
    &#34;&#34;&#34;Check if file is a generic container file.

    Supported file formats are:

    - python pickle files (.pkl)
    - numpy files (.npz)
    - matlab files (.mat)

    Parameters
    ----------
    filepath: str or Path
        Path of the file to check.
    
    Returns
    -------
    is_container: bool
        `True`, if `filepath` is a supported container format.
    &#34;&#34;&#34;
    ext = Path(filepath).suffix
    return ext.lower() in (&#39;.pkl&#39;, &#39;.npz&#39;, &#39;.mat&#39;)</code></pre>
</details>
<div class="desc"><p>Check if file is a generic container file.</p>
<p>Supported file formats are:</p>
<ul>
<li>python pickle files (.pkl)</li>
<li>numpy files (.npz)</li>
<li>matlab files (.mat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to check.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>is_container</code></strong> :&ensp;<code>bool</code></dt>
<dd><code>True</code>, if <code>filepath</code> is a supported container format.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.extract_container_data"><code class="name flex">
<span>def <span class="ident">extract_container_data</span></span>(<span>data_dict,<br>datakey=None,<br>samplekey=['rate', 'Fs', 'fs'],<br>timekey=['time'],<br>amplkey=['amax'],<br>unitkey='unit',<br>amax=1.0,<br>unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_container_data(data_dict, datakey=None,
                           samplekey=[&#39;rate&#39;, &#39;Fs&#39;, &#39;fs&#39;],
                           timekey=[&#39;time&#39;], amplkey=[&#39;amax&#39;], unitkey=&#39;unit&#39;,
                           amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Extract data from dictionary loaded from a container file.

    Parameters
    ----------
    data_dict: dict
        Dictionary of the data items contained in the container.
    datakey: None, str, or list of str
        Name of the variable holding the data.  If `None` take the
        variable that is an 2D array and has the largest number of
        elements.
    samplekey: str or list of str
        Name of the variable holding the sampling rate.
    timekey: str or list of str
        Name of the variable holding sampling times.
        If no sampling rate is available, the sampling rate is retrieved
        from the sampling times.
    amplkey: str or list of str
        Name of the variable holding the amplitude range of the data.
    unitkey: str
        Name of the variable holding the unit of the data.
    amax: None or float
        If specified and no amplitude range has been found in `data_dict`,
        then this is the amplitude range of the data.
    unit: None or str
        If specified and no unit has been found in `data_dict`,
        then return this as the unit of the data.

    Returns
    -------
    data: 2-D array of floats
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data.
    amax: float
        Maximum amplitude of data range in `unit`.

    Raises
    ------
    ValueError:
        Invalid key requested.
    &#34;&#34;&#34;
    # extract format data:
    if not isinstance(samplekey, (list, tuple, np.ndarray)):
        samplekey = (samplekey,)
    if not isinstance(timekey, (list, tuple, np.ndarray)):
        timekey = (timekey,)
    if not isinstance(amplkey, (list, tuple, np.ndarray)):
        amplkey = (amplkey,)
    rate = 0.0
    for skey in samplekey:
        if skey in data_dict:
            rate = float(data_dict[skey])
            break
    if rate == 0.0:
        for tkey in timekey:
            if tkey in data_dict:
                rate = 1.0/(data_dict[tkey][1] - data_dict[tkey][0])
                break
    if rate == 0.0:
        raise ValueError(f&#34;invalid keys {&#39;, &#39;.join(samplekey)} and {&#39;, &#39;.join(timekey)} for requesting sampling rate or sampling times&#34;)
    for akey in amplkey:
        if akey in data_dict:
            amax = float(data_dict[akey])
            break
    if unitkey in data_dict:
        unit = data_dict[unitkey]
    # get data array:
    raw_data = np.array([])
    if datakey:
        # try data keys:
        if not isinstance(datakey, (list, tuple, np.ndarray)):
            datakey = (datakey,)
        for dkey in datakey:
            if dkey in data_dict:
                raw_data = data_dict[dkey]
                break
        if len(raw_data) == 0:
            raise ValueError(f&#34;invalid key(s) {&#39;, &#39;.join(datakey)} for requesting data&#34;)
    else:
        # find largest 2D array:
        for d in data_dict:
            if hasattr(data_dict[d], &#39;shape&#39;):
                if 1 &lt;= len(data_dict[d].shape) &lt;= 2 and \
                   np.max(data_dict[d].shape) &gt; np.max(raw_data.shape):
                    raw_data = data_dict[d]
    if len(raw_data) == 0:
        raise ValueError(&#39;no data found&#39;)
    # make 2D:
    if len(raw_data.shape) == 1:
        raw_data = raw_data.reshape(-1, 1)
    # transpose if necessary:
    if np.argmax(raw_data.shape) &gt; 0:
        raw_data = raw_data.T
    # recode:
    if raw_data.dtype == np.dtype(&#39;int16&#39;):
        data = raw_data.astype(&#39;float32&#39;)
        data *= amax/2**15
    elif raw_data.dtype == np.dtype(&#39;int32&#39;):
        data = raw_data.astype(float)
        data *= amax/2**31
    elif raw_data.dtype == np.dtype(&#39;int64&#39;):
        data = raw_data.astype(float)
        data *= amax/2**63
    else:
        data = raw_data
    return data, rate, unit, amax</code></pre>
</details>
<div class="desc"><p>Extract data from dictionary loaded from a container file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of the data items contained in the container.</dd>
<dt><strong><code>datakey</code></strong> :&ensp;<code>None, str,</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the data.
If <code>None</code> take the
variable that is an 2D array and has the largest number of
elements.</dd>
<dt><strong><code>samplekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the sampling rate.</dd>
<dt><strong><code>timekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding sampling times.
If no sampling rate is available, the sampling rate is retrieved
from the sampling times.</dd>
<dt><strong><code>amplkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the amplitude range of the data.</dd>
<dt><strong><code>unitkey</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the variable holding the unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>If specified and no amplitude range has been found in <code>data_dict</code>,
then this is the amplitude range of the data.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>None</code> or <code>str</code></dt>
<dd>If specified and no unit has been found in <code>data_dict</code>,
then return this as the unit of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code> of <code>floats</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range in <code>unit</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="valueerror">Valueerror</h2>
<p>Invalid key requested.</p></div>
</dd>
<dt id="thunderlab.dataloader.load_container"><code class="name flex">
<span>def <span class="ident">load_container</span></span>(<span>filepath,<br>datakey=None,<br>samplekey=['rate', 'Fs', 'fs'],<br>timekey=['time'],<br>amplkey=['amax'],<br>unitkey='unit',<br>amax=1.0,<br>unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_container(filepath, datakey=None,
                   samplekey=[&#39;rate&#39;, &#39;Fs&#39;, &#39;fs&#39;],
                   timekey=[&#39;time&#39;], amplkey=[&#39;amax&#39;], unitkey=&#39;unit&#39;,
                   amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Load data from a generic container file.

    Supported file formats are:

    - python pickle files (.pkl)
    - numpy files (.npz)
    - matlab files (.mat)

    Parameters
    ----------
    filepath: str or Path
        Path of the file to load.
    datakey: None, str, or list of str
        Name of the variable holding the data.  If `None` take the
        variable that is an 2D array and has the largest number of
        elements.
    samplekey: str or list of str
        Name of the variable holding the sampling rate.
    timekey: str or list of str
        Name of the variable holding sampling times.
        If no sampling rate is available, the sampling rate is retrieved
        from the sampling times.
    amplkey: str
        Name of the variable holding the amplitude range of the data.
    unitkey: str
        Name of the variable holding the unit of the data.
        If `unitkey` is not a valid key, then return `unitkey` as the `unit`.
    amax: None or float
        If specified and no amplitude range has been found in the data
        container, then this is the amplitude range of the data.
    unit: None or str
        If specified and no unit has been found in the data container,
        then return this as the unit of the data.

    Returns
    -------
    data: 2-D array of floats
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data.
    amax: float
        Maximum amplitude of data range.

    Raises
    ------
    ValueError:
        Invalid key requested.
    &#34;&#34;&#34;
    # load data:
    data_dict = {}
    filepath = Path(filepath)
    ext = filepath.suffix.lower()
    if ext == &#39;.pkl&#39;:
        with open(filepath, &#39;rb&#39;) as f:
            data_dict = pickle.load(f)
    elif ext == &#39;.npz&#39;:
        data_dict = np.load(filepath)
    elif ext == &#39;.mat&#39;:
        from scipy.io import loadmat
        data_dict = loadmat(filepath, squeeze_me=True)
    return extract_container_data(data_dict, datakey, samplekey,
                                  timekey, amplkey, unitkey, amax, unit)</code></pre>
</details>
<div class="desc"><p>Load data from a generic container file.</p>
<p>Supported file formats are:</p>
<ul>
<li>python pickle files (.pkl)</li>
<li>numpy files (.npz)</li>
<li>matlab files (.mat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to load.</dd>
<dt><strong><code>datakey</code></strong> :&ensp;<code>None, str,</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the data.
If <code>None</code> take the
variable that is an 2D array and has the largest number of
elements.</dd>
<dt><strong><code>samplekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the sampling rate.</dd>
<dt><strong><code>timekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding sampling times.
If no sampling rate is available, the sampling rate is retrieved
from the sampling times.</dd>
<dt><strong><code>amplkey</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the variable holding the amplitude range of the data.</dd>
<dt><strong><code>unitkey</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the variable holding the unit of the data.
If <code>unitkey</code> is not a valid key, then return <code>unitkey</code> as the <code>unit</code>.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>If specified and no amplitude range has been found in the data
container, then this is the amplitude range of the data.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>None</code> or <code>str</code></dt>
<dd>If specified and no unit has been found in the data container,
then return this as the unit of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code> of <code>floats</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="valueerror">Valueerror</h2>
<p>Invalid key requested.</p></div>
</dd>
<dt id="thunderlab.dataloader.extract_container_metadata"><code class="name flex">
<span>def <span class="ident">extract_container_metadata</span></span>(<span>data_dict, metadatakey=['metadata', 'info'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_container_metadata(data_dict, metadatakey=[&#39;metadata&#39;, &#39;info&#39;]):
    &#34;&#34;&#34; Extract metadata from dictionary loaded from a container file.

    Parameters
    ----------
    data_dict: dict
        Dictionary of the data items contained in the container.
    metadatakey: str or list of str
        Name of the variable holding the metadata.

    Returns
    -------
    metadata: nested dict
        Nested dictionary with key-value pairs of the meta data.
    &#34;&#34;&#34;
    if not isinstance(metadatakey, (list, tuple, np.ndarray)):
        metadatakey = (metadatakey,)
    # get single metadata dictionary:
    for mkey in metadatakey:
        if mkey in data_dict:
            return data_dict[mkey]
    # collect all keys starting with metadatakey:
    metadata = {}
    for mkey in metadatakey:
        mkey += &#39;__&#39;
        for dkey in data_dict:
            if dkey[:len(mkey)] == mkey:
                v = data_dict[dkey]
                if hasattr(v, &#39;size&#39;) and v.ndim == 0:
                    v = v.item()
                metadata[dkey[len(mkey):]] = v
        if len(metadata) &gt; 0:
            return unflatten_metadata(metadata, sep=&#39;__&#39;)
    return metadata</code></pre>
</details>
<div class="desc"><p>Extract metadata from dictionary loaded from a container file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of the data items contained in the container.</dd>
<dt><strong><code>metadatakey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the metadata.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>metadata</code></strong> :&ensp;<code>nested dict</code></dt>
<dd>Nested dictionary with key-value pairs of the meta data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.metadata_container"><code class="name flex">
<span>def <span class="ident">metadata_container</span></span>(<span>filepath, metadatakey=['metadata', 'info'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def metadata_container(filepath, metadatakey=[&#39;metadata&#39;, &#39;info&#39;]):
    &#34;&#34;&#34; Read meta-data of a container file.

    Parameters
    ----------
    filepath: str or Path
        A container file.
    metadatakey: str or list of str
        Name of the variable holding the metadata.

    Returns
    -------
    metadata: nested dict
        Nested dictionary with key-value pairs of the meta data.
    &#34;&#34;&#34;
    data_dict = {}
    filepath = Path(filepath)
    ext = filepath.suffix.lower()
    if ext == &#39;.pkl&#39;:
        with open(filepath, &#39;rb&#39;) as f:
            data_dict = pickle.load(f)
    elif ext == &#39;.npz&#39;:
        data_dict = np.load(filepath)
    elif ext == &#39;.mat&#39;:
        from scipy.io import loadmat
        data_dict = loadmat(filepath, squeeze_me=True)
    return extract_container_metadata(data_dict, metadatakey)</code></pre>
</details>
<div class="desc"><p>Read meta-data of a container file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A container file.</dd>
<dt><strong><code>metadatakey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the metadata.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>metadata</code></strong> :&ensp;<code>nested dict</code></dt>
<dd>Nested dictionary with key-value pairs of the meta data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.extract_container_markers"><code class="name flex">
<span>def <span class="ident">extract_container_markers</span></span>(<span>data_dict,<br>poskey=['positions'],<br>spanskey=['spans'],<br>labelskey=['labels'],<br>descrkey=['descriptions'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_container_markers(data_dict, poskey=[&#39;positions&#39;],
                              spanskey=[&#39;spans&#39;], labelskey=[&#39;labels&#39;],
                              descrkey=[&#39;descriptions&#39;]):
    &#34;&#34;&#34; Extract markers from dictionary loaded from a container file.

    Parameters
    ----------
    data_dict: dict
        Dictionary of the data items contained in the container.
    poskey: str or list of str
        Name of the variable holding positions of markers.
    spanskey: str or list of str
        Name of the variable holding spans of markers.
    labelskey: str or list of str
        Name of the variable holding labels of markers.
    descrkey: str or list of str
        Name of the variable holding descriptions of markers.

    Returns
    -------
    locs: 2-D array of ints
        Marker positions (first column) and spans (second column)
        for each marker (rows).
    labels: 2-D array of string objects
        Labels (first column) and texts (second column)
        for each marker (rows).
    &#34;&#34;&#34;
    if not isinstance(poskey, (list, tuple, np.ndarray)):
        poskey = (poskey,)
    if not isinstance(spanskey, (list, tuple, np.ndarray)):
        spanskey = (spanskey,)
    if not isinstance(labelskey, (list, tuple, np.ndarray)):
        labelskey = (labelskey,)
    if not isinstance(descrkey, (list, tuple, np.ndarray)):
        descrkey = (descrkey,)
    locs = np.zeros((0, 2), dtype=int)
    for pkey in poskey:
        if pkey in data_dict:
            locs = np.zeros((len(data_dict[pkey]), 2), dtype=int)
            locs[:,0] = data_dict[pkey]
            break
    for skey in spanskey:
        if skey in data_dict:
            locs[:,1] = data_dict[skey]
            break
    labels = np.zeros((0, 2), dtype=object)
    for lkey in labelskey:
        if lkey in data_dict:
            labels = np.zeros((len(data_dict[lkey]), 2), dtype=object)
            labels[:,0] = data_dict[lkey]
            break
    for dkey in descrkey:
        if dkey in data_dict:
            labels[:,1] = data_dict[dkey]
            break
    return locs, labels</code></pre>
</details>
<div class="desc"><p>Extract markers from dictionary loaded from a container file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of the data items contained in the container.</dd>
<dt><strong><code>poskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding positions of markers.</dd>
<dt><strong><code>spanskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding spans of markers.</dd>
<dt><strong><code>labelskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding labels of markers.</dd>
<dt><strong><code>descrkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding descriptions of markers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locs</code></strong> :&ensp;<code>2-D array</code> of <code>ints</code></dt>
<dd>Marker positions (first column) and spans (second column)
for each marker (rows).</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>2-D array</code> of <code>string objects</code></dt>
<dd>Labels (first column) and texts (second column)
for each marker (rows).</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.markers_container"><code class="name flex">
<span>def <span class="ident">markers_container</span></span>(<span>filepath,<br>poskey=['positions'],<br>spanskey=['spans'],<br>labelskey=['labels'],<br>descrkey=['descriptions'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def markers_container(filepath, poskey=[&#39;positions&#39;],
                      spanskey=[&#39;spans&#39;], labelskey=[&#39;labels&#39;],
                      descrkey=[&#39;descriptions&#39;]):
    &#34;&#34;&#34; Read markers of a container file.

    Parameters
    ----------
    filepath: str or Path
        A container file.
    poskey: str or list of str
        Name of the variable holding positions of markers.
    spanskey: str or list of str
        Name of the variable holding spans of markers.
    labelskey: str or list of str
        Name of the variable holding labels of markers.
    descrkey: str or list of str
        Name of the variable holding descriptions of markers.

    Returns
    -------
    locs: 2-D array of ints
        Marker positions (first column) and spans (second column)
        for each marker (rows).
    labels: 2-D array of string objects
        Labels (first column) and texts (second column)
        for each marker (rows).
    &#34;&#34;&#34;
    data_dict = {}
    filepath = Path(filepath)
    ext = filepath.suffix.lower()
    if ext == &#39;.pkl&#39;:
        with open(filepath, &#39;rb&#39;) as f:
            data_dict = pickle.load(f)
    elif ext == &#39;.npz&#39;:
        data_dict = np.load(filepath)
    elif ext == &#39;.mat&#39;:
        from scipy.io import loadmat
        data_dict = loadmat(filepath, squeeze_me=True)
    return extract_container_markers(data_dict, poskey, spanskey,
                                     labelskey, descrkey)</code></pre>
</details>
<div class="desc"><p>Read markers of a container file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>A container file.</dd>
<dt><strong><code>poskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding positions of markers.</dd>
<dt><strong><code>spanskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding spans of markers.</dd>
<dt><strong><code>labelskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding labels of markers.</dd>
<dt><strong><code>descrkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding descriptions of markers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locs</code></strong> :&ensp;<code>2-D array</code> of <code>ints</code></dt>
<dd>Marker positions (first column) and spans (second column)
for each marker (rows).</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>2-D array</code> of <code>string objects</code></dt>
<dd>Labels (first column) and texts (second column)
for each marker (rows).</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.check_raw"><code class="name flex">
<span>def <span class="ident">check_raw</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_raw(filepath):
    &#34;&#34;&#34;Check if file is a raw file.

    The following extensions are interpreted as raw files:

    - raw files (*.raw)
    - LabView scandata (*.scandat)

    Parameters
    ----------
    filepath: str or Path
        Path of the file to check.
    
    Returns
    -------
    is_raw: bool
        `True`, if `filepath` is a raw format.
    &#34;&#34;&#34;
    ext = Path(filepath).suffix
    return ext.lower() in (&#39;.raw&#39;, &#39;.scandat&#39;)</code></pre>
</details>
<div class="desc"><p>Check if file is a raw file.</p>
<p>The following extensions are interpreted as raw files:</p>
<ul>
<li>raw files (*.raw)</li>
<li>LabView scandata (*.scandat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to check.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>is_raw</code></strong> :&ensp;<code>bool</code></dt>
<dd><code>True</code>, if <code>filepath</code> is a raw format.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.load_raw"><code class="name flex">
<span>def <span class="ident">load_raw</span></span>(<span>filepath, rate=44000, channels=1, encoding='FLOAT', amax=1.0, unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_raw(filepath, rate=44000, channels=1, encoding=&#39;FLOAT&#39;,
             amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Load data from a raw file.

    Raw files just contain the data and absolutely no metadata, not
    even the sampling rate, number of channels, etc.
    Supported file formats are:

    - raw files (*.raw)
    - LabView scandata (*.scandat)

    Parameters
    ----------
    filepath: str or Path
        Path of the file to load.
    rate: float
        Sampling rate of the data in Hertz.
    channels: int
        Number of channels multiplexed in the data.
    encoding: str
        The encoding of the data stored in the file.
        Valid encodings are &#39;PCM_16&#39;, &#39;PCM_32&#39;, &#39;PCM_64&#39;, &#39;FLOAT&#39;, or
        &#39;DOUBLE&#39; or lower-case versions thereof.
    amax: float
        The amplitude range of the data.
    unit: str
        The unit of the data.

    Returns
    -------
    data: 2-D array of floats
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data.
    amax: float
        Maximum amplitude of data range.

    Raises
    ------
    ValueError:
        Invalid encoding.

    &#34;&#34;&#34;
    encodings = {&#39;PCM_16&#39;: &#39;i2&#39;,
                 &#39;PCM_32&#39;: &#39;i4&#39;,
                 &#39;PCM_64&#39;: &#39;i8&#39;,
                 &#39;FLOAT&#39;: &#39;f&#39;,
                 &#39;DOUBLE&#39;: &#39;d&#39;}
    encoding = encoding.upper()
    if not encoding in encodings:
        raise ValueError(f&#39;invalid encoding {encoding} for raw file!&#39;)
    dtype = np.dtype(encodings[encoding])
    raw_data = np.fromfile(filepath, dtype=dtype).reshape(-1, channels)
    # recode:
    if dtype == np.dtype(&#39;int16&#39;):
        data = raw_data.astype(&#39;float32&#39;)
        data *= amax/2**15
    elif dtype == np.dtype(&#39;int32&#39;):
        data = raw_data.astype(float)
        data *= amax/2**31
    elif dtype == np.dtype(&#39;int64&#39;):
        data = raw_data.astype(float)
        data *= amax/2**63
    else:
        data = raw_data
    return data, rate, unit, amax</code></pre>
</details>
<div class="desc"><p>Load data from a raw file.</p>
<p>Raw files just contain the data and absolutely no metadata, not
even the sampling rate, number of channels, etc.
Supported file formats are:</p>
<ul>
<li>raw files (*.raw)</li>
<li>LabView scandata (*.scandat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to load.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hertz.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of channels multiplexed in the data.</dd>
<dt><strong><code>encoding</code></strong> :&ensp;<code>str</code></dt>
<dd>The encoding of the data stored in the file.
Valid encodings are 'PCM_16', 'PCM_32', 'PCM_64', 'FLOAT', or
'DOUBLE' or lower-case versions thereof.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>The amplitude range of the data.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>The unit of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code> of <code>floats</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="valueerror">Valueerror</h2>
<p>Invalid encoding.</p></div>
</dd>
<dt id="thunderlab.dataloader.load_audioio"><code class="name flex">
<span>def <span class="ident">load_audioio</span></span>(<span>filepath, verbose=0, gainkey=['AIMaxVolt', 'gain'], sep='.', amax=1.0, unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_audioio(filepath, verbose=0, gainkey=default_gain_keys, sep=&#39;.&#39;,
                 amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Load data from an audio file.

    See the
    [`load_audio()`](https://bendalab.github.io/audioio/api/audioloader.html#audioio.audioloader.load_audio)
    function of the [`audioio`](https://github.com/bendalab/audioio)
    package for more infos.

    Parameters
    ----------
    filepath: str or Path
        Path of the file to load.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    gainkey: str or list of str
        Key in the file&#39;s metadata that holds some gain information.
        If found, the data will be multiplied with the gain,
        and if available, the corresponding unit is returned.
        See the [audioio.get_gain()](https://bendalab.github.io/audioio/api/audiometadata.html#audioio.audiometadata.get_gain) function for details.
    sep: str
        String that separates section names in `gainkey`.
    amax: float
        If specified and no gain has been found in the metadata,
        then use this as the amplitude range.
    unit: str
        If specified and no gain has been found in the metadata,
        then return this as the unit of the data.

    Returns
    -------
    data: 2-D array of floats
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data if found in the metadata (see `gainkey`),
        otherwise `unit`.
    amax: float
        Maximum amplitude of data range.
    &#34;&#34;&#34;
    # get gain:
    md = metadata_audioio(filepath)
    amax, unit = get_gain(md, gainkey, sep, amax, unit)
    # load data:
    data, rate = load_audio(filepath, verbose)
    if amax != 1.0:
        data *= amax
    return data, rate, unit, amax</code></pre>
</details>
<div class="desc"><p>Load data from an audio file.</p>
<p>See the
<a href="https://bendalab.github.io/audioio/api/audioloader.html#audioio.audioloader.load_audio"><code>load_audio()</code></a>
function of the <a href="https://github.com/bendalab/audioio"><code>audioio</code></a>
package for more infos.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to load.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>gainkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Key in the file's metadata that holds some gain information.
If found, the data will be multiplied with the gain,
and if available, the corresponding unit is returned.
See the <a href="https://bendalab.github.io/audioio/api/audiometadata.html#audioio.audiometadata.get_gain">audioio.get_gain()</a> function for details.</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>String that separates section names in <code>gainkey</code>.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>If specified and no gain has been found in the metadata,
then use this as the amplitude range.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>If specified and no gain has been found in the metadata,
then return this as the unit of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code> of <code>floats</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data if found in the metadata (see <code>gainkey</code>),
otherwise <code>unit</code>.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>filepath, verbose=0, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(filepath, verbose=0, **kwargs):
    &#34;&#34;&#34;Load time-series data from a file.

    Parameters
    ----------
    filepath: str or Path
        Path and name of the file to load.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    **kwargs: dict
        Further keyword arguments that are passed on to the 
        format specific loading functions.
        For example:
        - `amax`: the amplitude range of the data.
        - &#39;unit&#39;: the unit of the data.

    Returns
    -------
    data: 2-D array
        All data traces as an 2-D numpy array, even for single channel data.
        First dimension is time, second is channel.
    rate: float
        Sampling rate of the data in Hz.
    unit: str
        Unit of the data.
    amax: float
        Maximum amplitude of data range.
    &#34;&#34;&#34;
    # load data:
    for name, check_file, load_file, _, _ in  data_loader_funcs:
        if check_file is None or check_file(filepath):
            data, rate, unit, amax = load_file(filepath, **kwargs)
            if verbose &gt; 0:
                print(f&#39;loaded {name} data from file &#34;{filepath}&#34;&#39;)
                if verbose &gt; 1:
                    print(f&#39;  sampling rate: {rate:g} Hz&#39;)
                    print(f&#39;  channels     : {data.shape[1]}&#39;)
                    print(f&#39;  frames       : {len(data)}&#39;)
                    print(f&#39;  range        : {amax:g}{unit}&#39;)
            return data, rate, unit, amax
    return np.zeros((0, 1)), 0.0, &#39;&#39;, 1.0</code></pre>
</details>
<div class="desc"><p>Load time-series data from a file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path and name of the file to load.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Further keyword arguments that are passed on to the
format specific loading functions.
For example:
- <code>amax</code>: the amplitude range of the data.
- 'unit': the unit of the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>2-D array</code></dt>
<dd>All data traces as an 2-D numpy array, even for single channel data.
First dimension is time, second is channel.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hz.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude of data range.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.metadata"><code class="name flex">
<span>def <span class="ident">metadata</span></span>(<span>filepath, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def metadata(filepath, **kwargs):
    &#34;&#34;&#34; Read meta-data from a data file.

    Parameters
    ----------
    filepath: str or Path
        The full path and name of the file to load. For some file
        formats several files can be provided in a list.
    **kwargs: dict
        Further keyword arguments that are passed on to the 
        format specific loading functions.

    Returns
    -------
    meta_data: nested dict
        Meta data contained in the file.  Keys of the nested
        dictionaries are always strings.  If the corresponding
        values are dictionaries, then the key is the section name
        of the metadata contained in the dictionary. All other
        types of values are values for the respective key. In
        particular they are strings, or list of strings. But other
        simple types like ints or floats are also allowed.
    &#34;&#34;&#34;
    # load metadata:
    for _, check_file, _, metadata_file, _ in  data_loader_funcs:
        if check_file is None or check_file(filepath):
            if metadata_file is not None:
                return metadata_file(filepath, **kwargs)
    return {}</code></pre>
</details>
<div class="desc"><p>Read meta-data from a data file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>The full path and name of the file to load. For some file
formats several files can be provided in a list.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Further keyword arguments that are passed on to the
format specific loading functions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>meta_data</code></strong> :&ensp;<code>nested dict</code></dt>
<dd>Meta data contained in the file.
Keys of the nested
dictionaries are always strings.
If the corresponding
values are dictionaries, then the key is the section name
of the metadata contained in the dictionary. All other
types of values are values for the respective key. In
particular they are strings, or list of strings. But other
simple types like ints or floats are also allowed.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.markers"><code class="name flex">
<span>def <span class="ident">markers</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def markers(filepath):
    &#34;&#34;&#34; Read markers of a data file.

    Parameters
    ----------
    filepath: str or Path
        The data file.

    Returns
    -------
    locs: 2-D array of ints
        Marker positions (first column) and spans (second column)
        for each marker (rows).
    labels: 2-D array of string objects
        Labels (first column) and texts (second column)
        for each marker (rows).
    &#34;&#34;&#34;
    # load markers:
    for _, check_file, _, _, markers_file in  data_loader_funcs:
        if check_file is None or check_file(filepath):
            if markers_file is not None:
                return markers_file(filepath)
    return np.zeros((0, 2), dtype=int), np.zeros((0, 2), dtype=object)</code></pre>
</details>
<div class="desc"><p>Read markers of a data file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>The data file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locs</code></strong> :&ensp;<code>2-D array</code> of <code>ints</code></dt>
<dd>Marker positions (first column) and spans (second column)
for each marker (rows).</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>2-D array</code> of <code>string objects</code></dt>
<dd>Labels (first column) and texts (second column)
for each marker (rows).</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.demo"><code class="name flex">
<span>def <span class="ident">demo</span></span>(<span>filepath, plot=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def demo(filepath, plot=False):
    print(&#34;try load_data:&#34;)
    data, rate, unit, amax = load_data(filepath, verbose=2)
    if plot:
        fig, ax = plt.subplots()
        time = np.arange(len(data))/rate
        for c in range(data.shape[1]):
            ax.plot(time, data[:,c])
        ax.set_xlabel(&#39;Time [s]&#39;)
        ax.set_ylabel(f&#39;[{unit}]&#39;)
        if amax is not None and np.isfinite(amax):
            ax.set_ylim(-amax, +amax)
        plt.show()
        return

    print(&#39;&#39;)
    print(&#34;try DataLoader:&#34;)
    with DataLoader(filepath, 2.0, 1.0, 1) as data:
        print(&#39;sampling rate: %g&#39; % data.rate)
        print(&#39;frames       : %d %d&#39; % (len(data), data.shape[0]))
        nframes = int(1.0 * data.rate)
        # forward:
        for i in range(0, len(data), nframes):
            print(&#39;forward %d-%d&#39; % (i, i + nframes))
            x = data[i:i + nframes, 0]
            if plot:
                fig, ax = plt.subplots()
                ax.plot((i + np.arange(len(x)))/data.rate, x)
                ax.set_xlabel(&#39;Time [s]&#39;)
                ax.set_ylabel(f&#39;[{data.unit}]&#39;)
                plt.show()
        # and backwards:
        for i in reversed(range(0, len(data), nframes)):
            print(&#39;backward %d-%d&#39; % (i, i + nframes))
            x = data[i:i + nframes, 0]
            if plot:
                fig, ax = plt.subplots()
                ax.plot((i + np.arange(len(x)))/data.rate, x)
                ax.set_xlabel(&#39;Time [s]&#39;)
                ax.set_ylabel(f&#39;[{data.unit}]&#39;)
                plt.show()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="thunderlab.dataloader.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>*cargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(*cargs):
    &#34;&#34;&#34;Call demo with command line arguments.

    Parameters
    ----------
    cargs: list of str
        Command line arguments as provided by sys.argv[1:]
    &#34;&#34;&#34;
    import argparse
    parser = argparse.ArgumentParser(description=
                                     &#39;Checking thunderlab.dataloader module.&#39;)
    parser.add_argument(&#39;-p&#39;, dest=&#39;plot&#39;, action=&#39;store_true&#39;,
                        help=&#39;plot loaded data&#39;)
    parser.add_argument(&#39;file&#39;, nargs=1, default=&#39;&#39;, type=str,
                        help=&#39;name of data file&#39;)
    args = parser.parse_args(cargs)
    demo(args.file[0], args.plot)</code></pre>
</details>
<div class="desc"><p>Call demo with command line arguments.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cargs</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>Command line arguments as provided by sys.argv[1:]</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="thunderlab.dataloader.DataLoader"><code class="flex name class">
<span>class <span class="ident">DataLoader</span></span>
<span>(</span><span>filepath=None, buffersize=10.0, backsize=0.0, verbose=0, meta_kwargs={}, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataLoader(AudioLoader):
    &#34;&#34;&#34;Buffered reading of time-series data for random access of the data in the file.
    
    This allows for reading very large data files that do not fit into
    memory.  A `DataLoader` instance can be used like a huge
    read-only numpy array, i.e.
    ```
    data = DataLoader(&#39;path/to/data/file.dat&#39;)
    x = data[10000:20000,0]
    ```
    The first index specifies the frame, the second one the channel.

    `DataLoader` first determines the format of the data file and then
    opens the file (first line). It then reads data from the file as
    necessary for the requested data (second line).

    Supported file formats are
    
    - python pickle files
    - numpy .npz files
    - matlab .mat files
    - audio files via [`audioio`](https://github.com/bendalab/audioio) package
    - LabView .scandat files
    - raw files
    - relacs files (https://www.relacs.net)
    - fishgrid files (https://github.com/bendalab/fishgrid)

    Reading sequentially through the file is always possible. If
    previous data are requested, then the file is read from the
    beginning. This might slow down access to previous data
    considerably. Use the `backsize` argument to the open functions to
    make sure some data are loaded before the requested frame. Then a
    subsequent access to the data within `backsize` seconds before that
    frame can still be handled without the need to reread the file
    from the beginning.

    Usage:
    ------
    ```
    import thunderlab.dataloader as dl
    with dl.DataLoader(filepath, 60.0, 10.0) as data:
        # do something with the content of the file:
        x = data[0:10000,0]
        y = data[10000:20000,0]
        z = x + y
    ```
    
    Normal open and close:
    ```
    data = dl.DataLoader(filepath, 60.0)
    x = data[:,:]  # read the whole file
    data.close()
    ```    
    that is the same as:
    ```
    data = dl.DataLoader()
    data.open(filepath, 60.0)
    ```
    
    Parameters
    ----------
    filepath: str or Path
        Path of the data file.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If larger than zero show detailed error/warning messages.
    meta_kwargs: dict
        Keyword arguments that are passed on to the _load_metadata() function.
    **kwargs: dict
        Further keyword arguments that are passed on to the 
        specific open() functions.

    Attributes
    ----------
    filepath: Path
        Name and path of the opened file. In case of many files, the first one.
    file_paths: list of Path
        List of pathes of the opened files that are made accessible
        as a single array.
    file_indices: list of int
        For each file the index of its first sample.
    rate: float
        The sampling rate of the data in Hertz.
    channels: int
        The number of channels that are read in.
    frames: int
        The number of frames in the file.
    format: str or None
        Format of the audio file.
    encoding: str or None
        Encoding/subtype of the audio file.
    shape: tuple
        Number of frames and channels of the data.
    ndim: int
        Number of dimensions: always 2 (frames and channels).
    offset: int
        Index of first frame in the current buffer.
    buffer: ndarray of floats
        The curently available data from the file.
    unit: str
        Unit of the data.
    ampl_min: float
        Minimum amplitude the file format supports.
    ampl_max: float
        Maximum amplitude the file format supports.

    Methods
    -------

    - `len()`: the number of frames
    - `open()`: open a data file.
    - `open_*()`: open a data file of a specific format.
    - `close()`: close the file.
    - `basename()`: Base name of the audio data.
    - `format_dict()`: technical infos about how the data are stored.
    - `metadata()`: metadata of the file.
    - `markers()`: markers of the file.
    - `set_unwrap()`: Set parameters for unwrapping clipped data.

    See audioio.audioloader.AudioLoader for more methods.

    &#34;&#34;&#34;

    def __init__(self, filepath=None, buffersize=10.0, backsize=0.0,
                 verbose=0, meta_kwargs={}, **kwargs):
        super().__init__(None, buffersize, backsize,
                         verbose, meta_kwargs)
        if filepath is not None:
            self.open(filepath, buffersize, backsize, verbose, **kwargs)

    def __getitem__(self, key):
        return super(DataLoader, self).__getitem__(key)
 
    def __next__(self):
        return super(DataLoader, self).__next__()

    
    # relacs interface:        
    def open_relacs(self, filepath, buffersize=10.0, backsize=0.0,
                    verbose=0, amax=1.0):
        &#34;&#34;&#34;Open relacs data files (www.relacs.net) for reading.

        Parameters
        ----------
        filepath: str
            Path to a relacs data directory or a file therein.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.
        amax: float
            The amplitude range of the data.

        Raises
        ------
        FileNotFoundError:
            Invalid or non existing fishgrid files.
        ValueError:
            .gz files not supported.
        &#34;&#34;&#34;
        self.verbose = verbose

        # open trace files:
        filepath = Path(filepath)
        self.trace_filepaths = relacs_trace_files(filepath)
        if len(self.trace_filepaths) == 0:
            raise FileNotFoundError(&#39;no relacs files found&#39;)
        self.sf = []
        self.frames = None
        self.rate = None
        self.unit = &#39;&#39;
        self.filepath = filepath
        self.file_paths = [self.filepath]
        self.file_indices = [0]
        for path in self.trace_filepaths:
            if path.suffix == &#39;.gz&#39;:
                raise ValueError(&#39;.gz files not supported&#39;)
            sf = open(path, &#39;rb&#39;)
            self.sf.append(sf)
            if self.verbose &gt; 0:
                print(f&#39;open_relacs(&#34;{path}&#34;)&#39;)
            # file size:
            sf.seek(0, os.SEEK_END)
            frames = sf.tell()//4
            if self.frames is None:
                self.frames = frames
            elif self.frames != frames:
                diff = self.frames - frames
                if diff &gt; 1 or diff &lt; -2:
                    raise ValueError(&#39;number of frames of traces differ&#39;)
                elif diff &gt;= 0:
                    self.frames = frames
            sf.seek(0)
            # retrieve sampling rate and unit:
            rate, us = relacs_samplerate_unit(path)
            if self.rate is None:
                self.rate = rate
            elif rate != self.rate:
                raise ValueError(&#39;sampling rates of traces differ&#39;)
            if len(self.unit) == 0:
                self.unit = us
            elif us != self.unit:
                raise ValueError(&#39;unit of traces differ&#39;)
        self.channels = len(self.sf)
        self.shape = (self.frames, self.channels)
        self.size = self.frames * self.channels
        self.ndim = len(self.shape)
        self.format = &#39;RELACS&#39;
        self.encoding = &#39;FLOAT&#39;
        self.bufferframes = int(buffersize*self.rate)
        self.backframes = int(backsize*self.rate)
        self.init_buffer()
        self.offset = 0
        self.close = self._close_relacs
        self.load_audio_buffer = self._load_buffer_relacs
        self.basename = self._basename_relacs
        self.ampl_min = -amax
        self.ampl_max = +amax
        self._load_metadata = metadata_relacs
        # TODO: load markers:
        self._locs = np.zeros((0, 2), dtype=int)
        self._labels = np.zeros((0, 2), dtype=object)
        self._load_markers = None
        return self

    def _close_relacs(self):
        &#34;&#34;&#34;Close the relacs data files.
        &#34;&#34;&#34;
        for f in self.sf:
            f.close()
        self.sf = []

    def _load_buffer_relacs(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load new data from relacs data file.

        Parameters
        ----------
        r_offset: int
           First frame to be read from file.
        r_size: int
           Number of frames to be read from file.
        buffer: ndarray
           Buffer where to store the loaded data.
        &#34;&#34;&#34;
        if len(self.sf) == 0 and len(self.trace_filepaths) &gt; 0:
            for path in self.trace_filepaths:
                self.sf.append(open(path, &#39;rb&#39;))
        for i, f in enumerate(self.sf):
            f.seek(r_offset*4)
            data = f.read(r_size*4)
            buffer[:, i] = np.frombuffer(data, dtype=np.float32)
        

    def _basename_relacs(self, path=None):
        &#34;&#34;&#34; Base name of the relacs data files.

        Parameters
        ----------
        path: str or None
            Path of a relacs data file (*.raw, info.dat, or just the directory).
            If `None`, use `self.filepath`.

        Returns
        -------
        s: str
            The base name, i.e. the name of the directory containing the
            relacs data files.

        &#34;&#34;&#34;
        if path is None:
            path = self.filepath
        else:
            path = Path(path)
        if path.is_dir():
            return path.name
        else:
            return path.parent.name

    
    # fishgrid interface:        
    def open_fishgrid(self, filepath, buffersize=10.0, backsize=0.0,
                      verbose=0):
        &#34;&#34;&#34;Open fishgrid data files (https://github.com/bendalab/fishgrid) for reading.

        Parameters
        ----------
        filepath: str
            Path to a fishgrid data directory, or a file therein.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.

        Raises
        ------
        FileNotFoundError:
            Invalid or non existing fishgrid files.
        ValueError:
            .gz files not supported.
        &#34;&#34;&#34;
        self.verbose = verbose

        filepath = Path(filepath)
        self.trace_filepaths = fishgrid_trace_files(filepath)
        if len(self.trace_filepaths) == 0:
            raise FileNotFoundError(f&#39;no fishgrid files found&#39;)
        self.filepath = filepath
        self.file_paths = [self.filepath]
        self.file_indices = [0]
        self._load_metadata = metadata_fishgrid
        self._load_markers = markers_fishgrid

        # open grid files:
        grids = fishgrid_grids(self.metadata())
        grid_sizes = [r*c for r,c in grids]
        self.channels = 0
        for g, path in enumerate(self.trace_filepaths):
            self.channels += grid_sizes[g]
        self.sf = []
        self.grid_channels = []
        self.grid_offs = []
        offs = 0
        self.frames = None
        self.rate = get_number(self.metadata(), &#39;Hz&#39;, &#39;AISampleRate&#39;)
        v, self.unit = get_number_unit(self.metadata(), &#39;AIMaxVolt&#39;)
        if v is not None:
            self.ampl_min = -v
            self.ampl_max = +v
            
        for g, path in enumerate(self.trace_filepaths):
            if path.suffix == &#39;.gz&#39;:
                raise ValueError(&#39;.gz files not supported&#39;)
            sf = open(path, &#39;rb&#39;)
            self.sf.append(sf)
            if self.verbose &gt; 0:
                print(f&#39;open_fishgrid(&#34;{path}&#34;)&#39;)
            # grid channels:
            self.grid_channels.append(grid_sizes[g])
            self.grid_offs.append(offs)
            offs += grid_sizes[g]
            # file size:
            sf.seek(0, os.SEEK_END)
            frames = sf.tell()//4//grid_sizes[g]
            if self.frames is None:
                self.frames = frames
            elif self.frames != frames:
                diff = self.frames - frames
                if diff &gt; 1 or diff &lt; -2:
                    raise ValueError(&#39;number of frames of traces differ&#39;)
                elif diff &gt;= 0:
                    self.frames = frames
            sf.seek(0)
        self.shape = (self.frames, self.channels)
        self.size = self.frames * self.channels
        self.ndim = len(self.shape)
        self.format = &#39;FISHGRID&#39;
        self.encoding = &#39;FLOAT&#39;
        self.bufferframes = int(buffersize*self.rate)
        self.backframes = int(backsize*self.rate)
        self.init_buffer()
        self.offset = 0
        self.close = self._close_fishgrid
        self.load_audio_buffer = self._load_buffer_fishgrid
        self.basename = self._basename_fishgrid
        return self

    def _close_fishgrid(self):
        &#34;&#34;&#34;Close the fishgrid data files.
        &#34;&#34;&#34;
        for file in self.sf:
            file.close()
        self.sf = []

    def _load_buffer_fishgrid(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load new data from relacs data file.

        Parameters
        ----------
        r_offset: int
           First frame to be read from file.
        r_size: int
           Number of frames to be read from file.
        buffer: ndarray
           Buffer where to store the loaded data.
        &#34;&#34;&#34;
        if len(self.sf) == 0 and len(self.trace_filepaths) &gt; 0:
            for path in self.trace_filepaths:
                self.sf.append(open(path, &#39;rb&#39;))
        for file, gchannels, goffset in zip(self.sf, self.grid_channels, self.grid_offs):
            file.seek(r_offset*4*gchannels)
            data = file.read(r_size*4*gchannels)
            buffer[:, goffset:goffset+gchannels] = np.frombuffer(data, dtype=np.float32).reshape((-1, gchannels))

    def _basename_fishgrid(self, path=None):
        &#34;&#34;&#34; Base name of the fishgrid data files.

        Parameters
        ----------
        path: str or Path or None
            Path of a fishgrid data file
            (*.raw, fishgrid.cfg, or just the directory).
            If `None`, use `self.filepath`.

        Returns
        -------
        s: str
            The base name, i.e. the name of the directory containing the
            fishgrid data files.

        &#34;&#34;&#34;
        if path is None:
            path = self.filepath
        else:
            path = Path(path)
        if path.is_dir():
            return path.name
        else:
            return path.parent.name



    # container interface:
    def open_container(self, filepath, buffersize=10.0,
                       backsize=0.0, verbose=0, datakey=None,
                       samplekey=[&#39;rate&#39;, &#39;Fs&#39;, &#39;fs&#39;],
                       timekey=[&#39;time&#39;], amplkey=[&#39;amax&#39;], unitkey=&#39;unit&#39;,
                       metadatakey=[&#39;metadata&#39;, &#39;info&#39;],
                       poskey=[&#39;positions&#39;],
                       spanskey=[&#39;spans&#39;], labelskey=[&#39;labels&#39;],
                       descrkey=[&#39;descriptions&#39;],
                       amax=1.0, unit=&#39;a.u.&#39;):
        &#34;&#34;&#34;Open generic container file.

        Supported file formats are:

        - python pickle files (.pkl)
        - numpy files (.npz)
        - matlab files (.mat)

        Parameters
        ----------
        filepath: str
            Path to a container file.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.
        datakey: None, str, or list of str
            Name of the variable holding the data.  If `None` take the
            variable that is an 2D array and has the largest number of
            elements.
        samplekey: str or list of str
            Name of the variable holding the sampling rate.
        timekey: str or list of str
            Name of the variable holding sampling times.
            If no sampling rate is available, the sampling rate is retrieved
            from the sampling times.
        amplkey: str or list of str
            Name of the variable holding the amplitude range of the data.
        unitkey: str
            Name of the variable holding the unit of the data.
        metadatakey: str or list of str
            Name of the variable holding the metadata.
        poskey: str or list of str
            Name of the variable holding positions of markers.
        spanskey: str or list of str
            Name of the variable holding spans of markers.
        labelskey: str or list of str
            Name of the variable holding labels of markers.
        descrkey: str or list of str
            Name of the variable holding descriptions of markers.
        amax: None or float
            If specified and no amplitude range has been found in the data
            container, then this is the amplitude range of the data.
        unit: None or str
            If specified and no unit has been found in the data container,
            then return this as the unit of the data.

        Raises
        ------
        ValueError:
            Invalid key requested.
        &#34;&#34;&#34;
        self.verbose = verbose
        data_dict = {}
        filepath = Path(filepath)
        ext = filepath.suffix.lower()
        if ext == &#39;.pkl&#39;:
            with open(filepath, &#39;rb&#39;) as f:
                data_dict = pickle.load(f)
            self.format = &#39;PKL&#39;
        elif ext == &#39;.npz&#39;:
            data_dict = np.load(filepath)
            self.format = &#39;NPZ&#39;
        elif ext == &#39;.mat&#39;:
            from scipy.io import loadmat
            data_dict = loadmat(filepath, squeeze_me=True)
            self.format = &#39;MAT&#39;
        if self.verbose &gt; 0:
            print(f&#39;open_container(&#34;{filepath}&#34;)&#39;)
        self.buffer, self.rate, self.unit, amax = \
            extract_container_data(data_dict, datakey, samplekey,
                                   timekey, amplkey, unitkey, amax, unit)
        self.filepath = filepath
        self.file_paths = [self.filepath]
        self.file_indices = [0]
        self.channels = self.buffer.shape[1]
        self.frames = self.buffer.shape[0]
        self.shape = self.buffer.shape
        self.ndim = self.buffer.ndim
        self.size = self.buffer.size
        self.encoding = self.numpy_encodings[self.buffer.dtype]
        self.ampl_min = -amax
        self.ampl_max = +amax
        self.offset = 0
        self.buffer_changed = np.zeros(self.channels, dtype=bool)
        self.bufferframes = self.frames
        self.backsize = 0
        self.close = self._close_container
        self.load_audio_buffer = self._load_buffer_container
        self._metadata = extract_container_metadata(data_dict, metadatakey)
        self._load_metadata = None
        self._locs, self._labels = extract_container_markers(data_dict,
                                                             poskey,
                                                             spanskey,
                                                             labelskey,
                                                             descrkey)
        self._load_markers = None

    def _close_container(self):
        &#34;&#34;&#34;Close container. &#34;&#34;&#34;
        pass

    def _load_buffer_container(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load new data from container.&#34;&#34;&#34;
        buffer[:, :] = self.buffer[r_offset:r_offset + r_size, :]


    # raw data interface:
    def open_raw(self, filepath, buffersize=10.0, backsize=0.0,
                 verbose=0, rate=44000, channels=1, encoding=&#39;FLOAT&#39;,
                 amax=1.0, unit=&#39;a.u.&#39;):
        &#34;&#34;&#34;Load data from a raw file.

        Raw files just contain the data and absolutely no metadata, not
        even the smapling rate, number of channels, etc.
        Supported file formats are:

        - raw files (*.raw)
        - LabView scandata (*.scandat)

        Parameters
        ----------
        filepath: str or Path
            Path of the file to load.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.
        rate: float
            Sampling rate of the data in Hertz.
        channels: int
            Number of channels multiplexed in the data.
        encoding: str
            The encoding of the data stored in the file.
            Valid encodings are &#39;PCM_16&#39;, &#39;PCM_32&#39;, &#39;PCM_64&#39;, &#39;FLOAT&#39;, or
            &#39;DOUBLE&#39; or lower-case versions thereof.
        amax: float
            The amplitude range of the data.
        unit: str
            The unit of the data.
        &#34;&#34;&#34;
        encodings = {&#39;PCM_16&#39;: &#39;i2&#39;,
                     &#39;PCM_32&#39;: &#39;i4&#39;,
                     &#39;PCM_64&#39;: &#39;i8&#39;,
                     &#39;FLOAT&#39;: &#39;f&#39;,
                     &#39;DOUBLE&#39;: &#39;d&#39;}
        encoding = encoding.upper()
        if not encoding in encodings:
            raise ValueError(f&#39;invalid encoding {encoding} for raw file!&#39;)
        self.dtype = np.dtype(encodings[encoding])
        self.verbose = verbose
        self.filepath = Path(filepath)
        self.file_paths = [self.filepath]
        self.file_indices = [0]
        self.sf = open(self.filepath, &#39;rb&#39;)
        if self.verbose &gt; 0:
            print(f&#39;open_raw(&#34;{self.filepath}&#34;)&#39;)
        self.rate = float(rate)
        # file size:
        self.channels = int(channels)
        self.sf.seek(0, os.SEEK_END)
        self.frames = self.sf.tell()//self.dtype.itemsize//self.channels
        self.sf.seek(0)
        self.shape = (self.frames, self.channels)
        self.ndim = len(self.shape)
        self.size = self.frames*self.channels
        self.format = &#39;RAW&#39;
        self.encoding = self.numpy_encodings.get(self.dtype, &#39;UNKNOWN&#39;)
        self.unit = unit
        self.ampl_max = float(amax)
        self.ampl_min = -self.ampl_max
        self.offset = 0
        self.bufferframes = int(buffersize*self.rate)
        self.backframes = int(backsize*self.rate)
        self.init_buffer()
        self.close = self._close_raw
        self.load_audio_buffer = self._load_buffer_raw
        self._metadata = None
        self._load_metadata = None
        self._locs = None
        self._labels = None
        self._load_markers = None

    def _close_raw(self):
        &#34;&#34;&#34;Close raw file. &#34;&#34;&#34;
        if self.sf is not None:
            self.sf.close()
        self.sf = None

    def _load_buffer_raw(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load new data from container.&#34;&#34;&#34;
        if self.sf is None:
            self.sf = open(self.filepath, &#39;rb&#39;)
        self.sf.seek(r_offset*self.dtype.itemsize*self.channels)
        raw_data = self.sf.read(r_size*self.dtype.itemsize*self.channels)
        raw_data = np.frombuffer(raw_data, dtype=self.dtype)
        raw_data = raw_data.reshape(-1, self.channels)
        # recode:
        if self.dtype == np.dtype(&#39;int16&#39;):
            data = raw_data.astype(&#39;float32&#39;)
            data *= self.ampl_max/2**15
        elif self.dtype == np.dtype(&#39;int32&#39;):
            data = raw_data.astype(float)
            data *= self.ampl_max/2**31
        elif self.dtype == np.dtype(&#39;int64&#39;):
            data = raw_data.astype(float)
            data *= self.ampl_max/2**63
        else:
            data = raw_data
        buffer[:, :] = data

    
    # audioio interface:        
    def open_audioio(self, filepath, buffersize=10.0, backsize=0.0,
                     verbose=0, gainkey=default_gain_keys, sep=&#39;.&#39;,
                     amax=None, unit=&#39;a.u.&#39;):
        &#34;&#34;&#34;Open an audio file.

        See the [audioio](https://github.com/bendalab/audioio) package
        for details.

        Parameters
        ----------
        filepath: str
            Path to an audio file.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index
            in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.
        gainkey: str or list of str
            Key in the file&#39;s metadata that holds some gain information.
            If found, the data will be multiplied with the gain,
            and if available, the corresponding unit is returned.
            See the [audioio.get_gain()](https://bendalab.github.io/audioio/api/audiometadata.html#audioio.audiometadata.get_gain) function for details.
        sep: str
            String that separates section names in `gainkey`.
        amax: None or float
            If specified and no gain has been found in the metadata,
            then use this as the amplitude range.
        unit: None or str
            If specified and no gain has been found in the metadata,
            then this is the unit of the data.

        &#34;&#34;&#34;
        self.verbose = verbose
        super(DataLoader, self).open(filepath, buffersize, backsize, verbose)
        md = self.metadata()
        fac, unit = get_gain(md, gainkey, sep, amax, unit)
        if fac is None:
            self.gain_fac = 1.0 
        else:
            self.gain_fac = fac
            self._load_buffer_audio_org = self.load_audio_buffer
            self.load_audio_buffer = self._load_buffer_audioio
        self.ampl_min *= self.gain_fac
        self.ampl_max *= self.gain_fac
        self.unit = unit
        return self
    
    def _load_buffer_audioio(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load and scale new data from an audio file.

        Parameters
        ----------
        r_offset: int
           First frame to be read from file.
        r_size: int
           Number of frames to be read from file.
        buffer: ndarray
           Buffer where to store the loaded data.
        &#34;&#34;&#34;
        self._load_buffer_audio_org(r_offset, r_size, buffer)
        buffer *= self.gain_fac


    # open multiple files as one:
    def open_multiple(self, filepaths, buffersize=10.0, backsize=0.0,
                      verbose=0, mode=&#39;strict&#39;, rate=None, channels=None,
                      unit=None, amax=None, end_indices=None):
        &#34;&#34;&#34;Open multiple files as a single concatenated array.

        Parameters
        ----------
        filepaths: list of str or Path
            List of file paths of audio files.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index in seconds.
        verbose: int
            If larger than zero show detailed error/warning messages.
        mode: &#39;relaxed&#39; or &#39;strict&#39;
            If &#39;strict&#39;, only concatenate files if they contain
            a start time in their meta data.
        rate: float
            If provided, do a minimal initialization (no checking)
            using the provided sampling rate (in Hertz), channels,
            unit, maximum amplitude, and end_indices.
        channels: int
            If provided, do a minimal initialization (no checking)
            using the provided rate, number of channels,
            unit, maximum amplitude, and end_indices.
        unit: str
            If provided, do a minimal initialization (no checking)
            using the provided rate, number of channels,
            unit, maximum amplitude, and end_indices.
        amax: float
            If provided, do a minimal initialization (no checking)
            using the provided rate, number of channels,
            unit, maximum amplitude amax, and end_indices.
        end_indices: sequence of int
            If provided, do a minimal initialization (no checking)
            using the provided rate, channels,
            unit, maximum amplitude, and end_indices.

        Raises
        ------
        TypeError
            `filepaths` must be a sequence.
        ValueError
            Empty `filepaths`.
        FileNotFoundError
            `filepaths` does not contain a single valid file.

        &#34;&#34;&#34;
        if not isinstance(filepaths, (list, tuple, np.ndarray)):
            raise TypeError(&#39;input argument filepaths is not a sequence!&#39;)
        if len(filepaths) == 0:
            raise ValueError(&#39;input argument filepaths is empy sequence!&#39;)
        self.buffersize = buffersize
        self.backsize = backsize
        self.filepath = None
        self.file_paths = []
        self.open_files = []
        self.open_loaders = []
        self.data_files = []
        self.collect_counter = 0
        self.frames = 0
        self.start_indices = []
        self.end_indices = []
        self.start_time = None
        start_time = None
        self._metadata = {}
        self._locs = np.zeros((0, 2), dtype=int)
        self._labels = np.zeros((0, 2), dtype=object)
        if end_indices is not None:
            self.file_paths = [Path(fp) for fp in filepaths]
            self.filepath = self.file_paths[0]
            self.data_files = [None] * len(self.file_paths)
            self.frames = end_indices[-1]
            self.start_indices = [0] + list(end_indices[:-1])
            self.end_indices = end_indices
            self.format = None
            self.encoding = None
            self.rate = rate
            self.channels = channels
            self.unit = unit
            self.ampl_max = amax
            self.ampl_min = -amax
        else:
            for filepath in filepaths:
                try:
                    a = DataLoader(filepath, buffersize, backsize, verbose)
                except Exception as e:
                    if verbose &gt; 0:
                        print(e)
                    continue
                # collect metadata:
                md = a.metadata()
                fmd = flatten_metadata(md, True)
                add_metadata(self._metadata, fmd)
                if self.filepath is None:
                    # first file:
                    self.filepath = a.filepath
                    self.format = a.format
                    self.encoding = a.encoding
                    self.rate = a.rate
                    self.channels = a.channels
                    self.unit = a.unit
                    self.ampl_max = a.ampl_max
                    self.ampl_min = a.ampl_min
                    self.start_time = get_datetime(md)
                    start_time = self.start_time
                    stime = self.start_time
                else:
                    # check channels, rate, and amplitudes:
                    error_str = None
                    if a.channels != self.channels:
                        error_str = f&#39;number of channels differs: &#39; \
                                    f&#39;{a.channels} in {a.filepath} versus &#39; \
                                    f&#39;{self.channels} in {self.filepath}&#39;
                    if a.rate != self.rate:
                        error_str = f&#39;sampling rates differ: &#39; \
                                    f&#39;{a.rate} in {a.filepath} versus &#39; \
                                    f&#39;{self.rate} in {self.filepath}&#39;
                    if a.ampl_min != self.ampl_min:
                        error_str = f&#39;minimum amplitudes differ: &#39; \
                                    f&#39;{a.ampl_min} in {a.filepath} versus &#39; \
                                    f&#39;{self.ampl_min} in {self.filepath}&#39;
                    if a.ampl_max != self.ampl_max:
                        error_Str = f&#39;maximum amplitudes differ: &#39; \
                                    f&#39;{a.ampl_max} in {a.filepath} versus &#39; \
                                    f&#39;{self.ampl_max} in {self.filepath}&#39;
                    # check start time of recording:
                    stime = get_datetime(md)
                    if mode == &#39;strict&#39; and (start_time is None or stime is None):
                        error_str = &#39;file does not contain a start time in its meta data&#39;
                    if start_time is not None and stime is not None and \
                       abs(start_time - stime) &gt; timedelta(seconds=self._max_time_diff):
                        error_str = f&#39;start time does not indicate continuous recording: &#39; \
                                    f&#39;expected {start_time} instead of &#39; \
                                    f&#39;{stime} in {a.filepath}&#39;
                    if error_str is not None:
                        if verbose &gt; 0:
                            print(error_str)
                        a.close()
                        del a
                        break
                # markers:
                locs, labels = a.markers()
                locs[:,0] += self.frames
                self._locs = np.vstack((self._locs, locs))
                self._labels = np.vstack((self._labels, labels))
                # indices:
                self.start_indices.append(self.frames)
                self.frames += a.frames
                self.end_indices.append(self.frames)
                if stime is not None:
                    start_time = stime + timedelta(seconds=a.frames/a.rate)
                # add file to lists:
                self.file_paths.append(a.filepath)
                if len(self.open_files) &lt; AudioLoader.max_open_files:
                    self.open_files.append(a)
                else:
                    a.close()
                if len(self.open_loaders) &lt; AudioLoader.max_open_loaders:
                    self.data_files.append(a)
                    self.open_loaders.append(a)
                else:
                    a.close()
                    del a
                    self.data_files.append(None)
            if len(self.data_files) == 0:
                raise FileNotFoundError(&#39;input argument filepaths does not contain any valid audio file!&#39;)
            # set startime from first file:
            if self.start_time is not None:
                set_starttime(self._metadata, self.start_time)
        # setup infrastructure:
        self.file_indices = self.start_indices
        self.start_indices = np.array(self.start_indices)
        self.end_indices = np.array(self.end_indices)
        self.shape = (self.frames, self.channels)
        self.bufferframes = int(buffersize*self.rate)
        self.backframes = int(backsize*self.rate)
        self.init_buffer()
        self.close = self._close_multiple
        self.load_audio_buffer = self._load_buffer_multiple
        self._load_metadata = None
        self._load_markers = None
        return self

    def _close_multiple(self):
        &#34;&#34;&#34;Close all the data files. &#34;&#34;&#34;
        self.open_files = []
        self.open_loaders = []
        if hasattr(self, &#39;data_files&#39;):
            for a in self.data_files:
                if a is not None:
                    a.close()
        self.data_files = []
        self.filepath = None
        self.file_paths = []
        self.file_indices = []
        self.start_indices = []
        self.end_indices = []
        del self.data_files
        del self.open_files
        del self.open_loaders
        del self.start_indices
        del self.end_indices

    def _load_buffer_multiple(self, r_offset, r_size, buffer):
        &#34;&#34;&#34;Load new data from the underlying files.

        Parameters
        ----------
        r_offset: int
           First frame to be read from file.
        r_size: int
           Number of frames to be read from file.
        buffer: ndarray
           Buffer where to store the loaded data.
        &#34;&#34;&#34;
        offs = r_offset
        size = r_size
        boffs = 0
        ai = np.searchsorted(self.end_indices, offs, side=&#39;right&#39;)
        while size &gt; 0:
            if self.data_files[ai] is None:
                a = DataLoader(self.file_paths[ai],
                                self.buffersize, self.backsize, 0)
                self.data_files[ai] = a
                self.open_loaders.append(a)
                self.open_files.append(a)
                if len(self.open_files) &gt; AudioLoader.max_open_files:
                    a0 = self.open_files.pop(0)
                    a0.close()
                if len(self.open_loaders) &gt; AudioLoader.max_open_loaders:
                    a0 = self.open_loaders.pop(0)
                    self.data_files[self.data_files.index(a0)] = None
                    a0.close()
                    del a0
                    self.collect_counter += 1
                    if self.collect_counter &gt; AudioLoader.max_open_loaders//2:
                        gc.collect()   # takes time!
                        self.collect_counter = 0
            else:
                self.open_loaders.pop(self.open_loaders.index(self.data_files[ai]))
                self.open_loaders.append(self.data_files[ai])
            ai0 = offs - self.start_indices[ai]
            ai1 = offs + size
            if ai1 &gt; self.end_indices[ai]:
                ai1 = self.end_indices[ai]
            ai1 -= self.start_indices[ai]
            n = ai1 - ai0
            self.data_files[ai].load_audio_buffer(ai0, n,
                                                  buffer[boffs:boffs + n,:])
            if self.data_files[ai] in self.open_files:
                self.open_files.pop(self.open_files.index(self.data_files[ai]))
            self.open_files.append(self.data_files[ai])
            if len(self.open_files) &gt; AudioLoader.max_open_files:
                self.open_files[0].close()
                self.open_files.pop(0)
            boffs += n
            offs += n
            size -= n
            ai += 1

        
    def open(self, filepath, buffersize=10.0, backsize=0.0,
             verbose=0, **kwargs):
        &#34;&#34;&#34;Open file with time-series data for reading.

        Parameters
        ----------
        filepath: str or list of str
            Name of the file or list of many file names that should be
            made accessible as a single array.
        buffersize: float
            Size of internal buffer in seconds.
        backsize: float
            Part of the buffer to be loaded before the requested start index
            in seconds.
        verbose: int
            If &gt; 0 show detailed error/warning messages.
        **kwargs: dict
            Further keyword arguments that are passed on to the 
            format specific opening functions.
            For example:
            - `amax`: the amplitude range of the data.
            - &#39;unit&#39;: the unit of the data.

        Raises
        ------
        ValueError:
            `filepath` is empty string.
        &#34;&#34;&#34;
        # list of implemented open functions:
        data_open_funcs = (
            (&#39;relacs&#39;, check_relacs, self.open_relacs, 1),
            (&#39;fishgrid&#39;, check_fishgrid, self.open_fishgrid, 1),
            (&#39;container&#39;, check_container, self.open_container, 1),
            (&#39;raw&#39;, check_raw, self.open_raw, 1),
            (&#39;audioio&#39;, None, self.open_audioio, 0),
            )
        
        self.buffer = np.array([])
        self.rate = 0.0
        if not filepath:
            raise ValueError(&#39;input argument filepath is empty string.&#39;)
        if isinstance(filepath, (list, tuple, np.ndarray)):
            if len(filepath) &gt; 1:
                self.open_multiple(filepath, buffersize, backsize,
                                   verbose, **kwargs)
                if len(self.file_paths) &gt; 1:
                    return self
                filepath = self.file_paths[0]
                self.close()
            else:
                filepath = filepath[0]
        # open data:
        for name, check_file, open_file, v in  data_open_funcs:
            if check_file is None or check_file(filepath):
                open_file(filepath, buffersize, backsize, verbose, **kwargs)
                if v*verbose &gt; 1:
                    if self.format is not None:
                        print(f&#39;  format       : {self.format}&#39;)
                    if self.encoding is not None:
                        print(f&#39;  encoding     : {self.encoding}&#39;)
                    print(f&#39;  sampling rate: {self.rate} Hz&#39;)
                    print(f&#39;  channels     : {self.channels}&#39;)
                    print(f&#39;  frames       : {self.frames}&#39;)
                    print(f&#39;  range        : {self.ampl_max:g}{self.unit}&#39;)
                break
        return self</code></pre>
</details>
<div class="desc"><p>Buffered reading of time-series data for random access of the data in the file.</p>
<p>This allows for reading very large data files that do not fit into
memory.
A <code><a title="thunderlab.dataloader.DataLoader" href="#thunderlab.dataloader.DataLoader">DataLoader</a></code> instance can be used like a huge
read-only numpy array, i.e.</p>
<pre><code>data = DataLoader('path/to/data/file.dat')
x = data[10000:20000,0]
</code></pre>
<p>The first index specifies the frame, the second one the channel.</p>
<p><code><a title="thunderlab.dataloader.DataLoader" href="#thunderlab.dataloader.DataLoader">DataLoader</a></code> first determines the format of the data file and then
opens the file (first line). It then reads data from the file as
necessary for the requested data (second line).</p>
<p>Supported file formats are</p>
<ul>
<li>python pickle files</li>
<li>numpy .npz files</li>
<li>matlab .mat files</li>
<li>audio files via <a href="https://github.com/bendalab/audioio"><code>audioio</code></a> package</li>
<li>LabView .scandat files</li>
<li>raw files</li>
<li>relacs files (<a href="https://www.relacs.net">https://www.relacs.net</a>)</li>
<li>fishgrid files (<a href="https://github.com/bendalab/fishgrid">https://github.com/bendalab/fishgrid</a>)</li>
</ul>
<p>Reading sequentially through the file is always possible. If
previous data are requested, then the file is read from the
beginning. This might slow down access to previous data
considerably. Use the <code>backsize</code> argument to the open functions to
make sure some data are loaded before the requested frame. Then a
subsequent access to the data within <code>backsize</code> seconds before that
frame can still be handled without the need to reread the file
from the beginning.</p>
<h2 id="usage">Usage:</h2>
<pre><code>import thunderlab.dataloader as dl
with dl.DataLoader(filepath, 60.0, 10.0) as data:
    # do something with the content of the file:
    x = data[0:10000,0]
    y = data[10000:20000,0]
    z = x + y
</code></pre>
<p>Normal open and close:</p>
<pre><code>data = dl.DataLoader(filepath, 60.0)
x = data[:,:]  # read the whole file
data.close()
</code></pre>
<p>that is the same as:</p>
<pre><code>data = dl.DataLoader()
data.open(filepath, 60.0)
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the data file.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If larger than zero show detailed error/warning messages.</dd>
<dt><strong><code>meta_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments that are passed on to the _load_metadata() function.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Further keyword arguments that are passed on to the
specific open() functions.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>Path</code></dt>
<dd>Name and path of the opened file. In case of many files, the first one.</dd>
<dt><strong><code>file_paths</code></strong> :&ensp;<code>list</code> of <code>Path</code></dt>
<dd>List of pathes of the opened files that are made accessible
as a single array.</dd>
<dt><strong><code>file_indices</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>For each file the index of its first sample.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>The sampling rate of the data in Hertz.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of channels that are read in.</dd>
<dt><strong><code>frames</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of frames in the file.</dd>
<dt><strong><code>format</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Format of the audio file.</dd>
<dt><strong><code>encoding</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Encoding/subtype of the audio file.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Number of frames and channels of the data.</dd>
<dt><strong><code>ndim</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of dimensions: always 2 (frames and channels).</dd>
<dt><strong><code>offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of first frame in the current buffer.</dd>
<dt><strong><code>buffer</code></strong> :&ensp;<code>ndarray</code> of <code>floats</code></dt>
<dd>The curently available data from the file.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the data.</dd>
<dt><strong><code>ampl_min</code></strong> :&ensp;<code>float</code></dt>
<dd>Minimum amplitude the file format supports.</dd>
<dt><strong><code>ampl_max</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum amplitude the file format supports.</dd>
</dl>
<h2 id="methods">Methods</h2>
<ul>
<li><code>len()</code>: the number of frames</li>
<li><code>open()</code>: open a data file.</li>
<li><code>open_*()</code>: open a data file of a specific format.</li>
<li><code>close()</code>: close the file.</li>
<li><code>basename()</code>: Base name of the audio data.</li>
<li><code>format_dict()</code>: technical infos about how the data are stored.</li>
<li><code><a title="thunderlab.dataloader.metadata" href="#thunderlab.dataloader.metadata">metadata()</a></code>: metadata of the file.</li>
<li><code><a title="thunderlab.dataloader.markers" href="#thunderlab.dataloader.markers">markers()</a></code>: markers of the file.</li>
<li><code>set_unwrap()</code>: Set parameters for unwrapping clipped data.</li>
</ul>
<p>See audioio.audioloader.AudioLoader for more methods.</p>
<p>Construtor for initializing 2D arrays (times x channels).</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>audioio.audioloader.AudioLoader</li>
<li>audioio.bufferedarray.BufferedArray</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="thunderlab.dataloader.DataLoader.open_relacs"><code class="name flex">
<span>def <span class="ident">open_relacs</span></span>(<span>self, filepath, buffersize=10.0, backsize=0.0, verbose=0, amax=1.0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_relacs(self, filepath, buffersize=10.0, backsize=0.0,
                verbose=0, amax=1.0):
    &#34;&#34;&#34;Open relacs data files (www.relacs.net) for reading.

    Parameters
    ----------
    filepath: str
        Path to a relacs data directory or a file therein.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    amax: float
        The amplitude range of the data.

    Raises
    ------
    FileNotFoundError:
        Invalid or non existing fishgrid files.
    ValueError:
        .gz files not supported.
    &#34;&#34;&#34;
    self.verbose = verbose

    # open trace files:
    filepath = Path(filepath)
    self.trace_filepaths = relacs_trace_files(filepath)
    if len(self.trace_filepaths) == 0:
        raise FileNotFoundError(&#39;no relacs files found&#39;)
    self.sf = []
    self.frames = None
    self.rate = None
    self.unit = &#39;&#39;
    self.filepath = filepath
    self.file_paths = [self.filepath]
    self.file_indices = [0]
    for path in self.trace_filepaths:
        if path.suffix == &#39;.gz&#39;:
            raise ValueError(&#39;.gz files not supported&#39;)
        sf = open(path, &#39;rb&#39;)
        self.sf.append(sf)
        if self.verbose &gt; 0:
            print(f&#39;open_relacs(&#34;{path}&#34;)&#39;)
        # file size:
        sf.seek(0, os.SEEK_END)
        frames = sf.tell()//4
        if self.frames is None:
            self.frames = frames
        elif self.frames != frames:
            diff = self.frames - frames
            if diff &gt; 1 or diff &lt; -2:
                raise ValueError(&#39;number of frames of traces differ&#39;)
            elif diff &gt;= 0:
                self.frames = frames
        sf.seek(0)
        # retrieve sampling rate and unit:
        rate, us = relacs_samplerate_unit(path)
        if self.rate is None:
            self.rate = rate
        elif rate != self.rate:
            raise ValueError(&#39;sampling rates of traces differ&#39;)
        if len(self.unit) == 0:
            self.unit = us
        elif us != self.unit:
            raise ValueError(&#39;unit of traces differ&#39;)
    self.channels = len(self.sf)
    self.shape = (self.frames, self.channels)
    self.size = self.frames * self.channels
    self.ndim = len(self.shape)
    self.format = &#39;RELACS&#39;
    self.encoding = &#39;FLOAT&#39;
    self.bufferframes = int(buffersize*self.rate)
    self.backframes = int(backsize*self.rate)
    self.init_buffer()
    self.offset = 0
    self.close = self._close_relacs
    self.load_audio_buffer = self._load_buffer_relacs
    self.basename = self._basename_relacs
    self.ampl_min = -amax
    self.ampl_max = +amax
    self._load_metadata = metadata_relacs
    # TODO: load markers:
    self._locs = np.zeros((0, 2), dtype=int)
    self._labels = np.zeros((0, 2), dtype=object)
    self._load_markers = None
    return self</code></pre>
</details>
<div class="desc"><p>Open relacs data files (www.relacs.net) for reading.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to a relacs data directory or a file therein.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>The amplitude range of the data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="filenotfounderror">Filenotfounderror</h2>
<p>Invalid or non existing fishgrid files.</p>
<h2 id="valueerror">Valueerror</h2>
<p>.gz files not supported.</p></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open_fishgrid"><code class="name flex">
<span>def <span class="ident">open_fishgrid</span></span>(<span>self, filepath, buffersize=10.0, backsize=0.0, verbose=0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_fishgrid(self, filepath, buffersize=10.0, backsize=0.0,
                  verbose=0):
    &#34;&#34;&#34;Open fishgrid data files (https://github.com/bendalab/fishgrid) for reading.

    Parameters
    ----------
    filepath: str
        Path to a fishgrid data directory, or a file therein.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.

    Raises
    ------
    FileNotFoundError:
        Invalid or non existing fishgrid files.
    ValueError:
        .gz files not supported.
    &#34;&#34;&#34;
    self.verbose = verbose

    filepath = Path(filepath)
    self.trace_filepaths = fishgrid_trace_files(filepath)
    if len(self.trace_filepaths) == 0:
        raise FileNotFoundError(f&#39;no fishgrid files found&#39;)
    self.filepath = filepath
    self.file_paths = [self.filepath]
    self.file_indices = [0]
    self._load_metadata = metadata_fishgrid
    self._load_markers = markers_fishgrid

    # open grid files:
    grids = fishgrid_grids(self.metadata())
    grid_sizes = [r*c for r,c in grids]
    self.channels = 0
    for g, path in enumerate(self.trace_filepaths):
        self.channels += grid_sizes[g]
    self.sf = []
    self.grid_channels = []
    self.grid_offs = []
    offs = 0
    self.frames = None
    self.rate = get_number(self.metadata(), &#39;Hz&#39;, &#39;AISampleRate&#39;)
    v, self.unit = get_number_unit(self.metadata(), &#39;AIMaxVolt&#39;)
    if v is not None:
        self.ampl_min = -v
        self.ampl_max = +v
        
    for g, path in enumerate(self.trace_filepaths):
        if path.suffix == &#39;.gz&#39;:
            raise ValueError(&#39;.gz files not supported&#39;)
        sf = open(path, &#39;rb&#39;)
        self.sf.append(sf)
        if self.verbose &gt; 0:
            print(f&#39;open_fishgrid(&#34;{path}&#34;)&#39;)
        # grid channels:
        self.grid_channels.append(grid_sizes[g])
        self.grid_offs.append(offs)
        offs += grid_sizes[g]
        # file size:
        sf.seek(0, os.SEEK_END)
        frames = sf.tell()//4//grid_sizes[g]
        if self.frames is None:
            self.frames = frames
        elif self.frames != frames:
            diff = self.frames - frames
            if diff &gt; 1 or diff &lt; -2:
                raise ValueError(&#39;number of frames of traces differ&#39;)
            elif diff &gt;= 0:
                self.frames = frames
        sf.seek(0)
    self.shape = (self.frames, self.channels)
    self.size = self.frames * self.channels
    self.ndim = len(self.shape)
    self.format = &#39;FISHGRID&#39;
    self.encoding = &#39;FLOAT&#39;
    self.bufferframes = int(buffersize*self.rate)
    self.backframes = int(backsize*self.rate)
    self.init_buffer()
    self.offset = 0
    self.close = self._close_fishgrid
    self.load_audio_buffer = self._load_buffer_fishgrid
    self.basename = self._basename_fishgrid
    return self</code></pre>
</details>
<div class="desc"><p>Open fishgrid data files (<a href="https://github.com/bendalab/fishgrid">https://github.com/bendalab/fishgrid</a>) for reading.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to a fishgrid data directory, or a file therein.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="filenotfounderror">Filenotfounderror</h2>
<p>Invalid or non existing fishgrid files.</p>
<h2 id="valueerror">Valueerror</h2>
<p>.gz files not supported.</p></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open_container"><code class="name flex">
<span>def <span class="ident">open_container</span></span>(<span>self,<br>filepath,<br>buffersize=10.0,<br>backsize=0.0,<br>verbose=0,<br>datakey=None,<br>samplekey=['rate', 'Fs', 'fs'],<br>timekey=['time'],<br>amplkey=['amax'],<br>unitkey='unit',<br>metadatakey=['metadata', 'info'],<br>poskey=['positions'],<br>spanskey=['spans'],<br>labelskey=['labels'],<br>descrkey=['descriptions'],<br>amax=1.0,<br>unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_container(self, filepath, buffersize=10.0,
                   backsize=0.0, verbose=0, datakey=None,
                   samplekey=[&#39;rate&#39;, &#39;Fs&#39;, &#39;fs&#39;],
                   timekey=[&#39;time&#39;], amplkey=[&#39;amax&#39;], unitkey=&#39;unit&#39;,
                   metadatakey=[&#39;metadata&#39;, &#39;info&#39;],
                   poskey=[&#39;positions&#39;],
                   spanskey=[&#39;spans&#39;], labelskey=[&#39;labels&#39;],
                   descrkey=[&#39;descriptions&#39;],
                   amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Open generic container file.

    Supported file formats are:

    - python pickle files (.pkl)
    - numpy files (.npz)
    - matlab files (.mat)

    Parameters
    ----------
    filepath: str
        Path to a container file.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    datakey: None, str, or list of str
        Name of the variable holding the data.  If `None` take the
        variable that is an 2D array and has the largest number of
        elements.
    samplekey: str or list of str
        Name of the variable holding the sampling rate.
    timekey: str or list of str
        Name of the variable holding sampling times.
        If no sampling rate is available, the sampling rate is retrieved
        from the sampling times.
    amplkey: str or list of str
        Name of the variable holding the amplitude range of the data.
    unitkey: str
        Name of the variable holding the unit of the data.
    metadatakey: str or list of str
        Name of the variable holding the metadata.
    poskey: str or list of str
        Name of the variable holding positions of markers.
    spanskey: str or list of str
        Name of the variable holding spans of markers.
    labelskey: str or list of str
        Name of the variable holding labels of markers.
    descrkey: str or list of str
        Name of the variable holding descriptions of markers.
    amax: None or float
        If specified and no amplitude range has been found in the data
        container, then this is the amplitude range of the data.
    unit: None or str
        If specified and no unit has been found in the data container,
        then return this as the unit of the data.

    Raises
    ------
    ValueError:
        Invalid key requested.
    &#34;&#34;&#34;
    self.verbose = verbose
    data_dict = {}
    filepath = Path(filepath)
    ext = filepath.suffix.lower()
    if ext == &#39;.pkl&#39;:
        with open(filepath, &#39;rb&#39;) as f:
            data_dict = pickle.load(f)
        self.format = &#39;PKL&#39;
    elif ext == &#39;.npz&#39;:
        data_dict = np.load(filepath)
        self.format = &#39;NPZ&#39;
    elif ext == &#39;.mat&#39;:
        from scipy.io import loadmat
        data_dict = loadmat(filepath, squeeze_me=True)
        self.format = &#39;MAT&#39;
    if self.verbose &gt; 0:
        print(f&#39;open_container(&#34;{filepath}&#34;)&#39;)
    self.buffer, self.rate, self.unit, amax = \
        extract_container_data(data_dict, datakey, samplekey,
                               timekey, amplkey, unitkey, amax, unit)
    self.filepath = filepath
    self.file_paths = [self.filepath]
    self.file_indices = [0]
    self.channels = self.buffer.shape[1]
    self.frames = self.buffer.shape[0]
    self.shape = self.buffer.shape
    self.ndim = self.buffer.ndim
    self.size = self.buffer.size
    self.encoding = self.numpy_encodings[self.buffer.dtype]
    self.ampl_min = -amax
    self.ampl_max = +amax
    self.offset = 0
    self.buffer_changed = np.zeros(self.channels, dtype=bool)
    self.bufferframes = self.frames
    self.backsize = 0
    self.close = self._close_container
    self.load_audio_buffer = self._load_buffer_container
    self._metadata = extract_container_metadata(data_dict, metadatakey)
    self._load_metadata = None
    self._locs, self._labels = extract_container_markers(data_dict,
                                                         poskey,
                                                         spanskey,
                                                         labelskey,
                                                         descrkey)
    self._load_markers = None</code></pre>
</details>
<div class="desc"><p>Open generic container file.</p>
<p>Supported file formats are:</p>
<ul>
<li>python pickle files (.pkl)</li>
<li>numpy files (.npz)</li>
<li>matlab files (.mat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to a container file.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>datakey</code></strong> :&ensp;<code>None, str,</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the data.
If <code>None</code> take the
variable that is an 2D array and has the largest number of
elements.</dd>
<dt><strong><code>samplekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the sampling rate.</dd>
<dt><strong><code>timekey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding sampling times.
If no sampling rate is available, the sampling rate is retrieved
from the sampling times.</dd>
<dt><strong><code>amplkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the amplitude range of the data.</dd>
<dt><strong><code>unitkey</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the variable holding the unit of the data.</dd>
<dt><strong><code>metadatakey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding the metadata.</dd>
<dt><strong><code>poskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding positions of markers.</dd>
<dt><strong><code>spanskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding spans of markers.</dd>
<dt><strong><code>labelskey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding labels of markers.</dd>
<dt><strong><code>descrkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the variable holding descriptions of markers.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>If specified and no amplitude range has been found in the data
container, then this is the amplitude range of the data.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>None</code> or <code>str</code></dt>
<dd>If specified and no unit has been found in the data container,
then return this as the unit of the data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="valueerror">Valueerror</h2>
<p>Invalid key requested.</p></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open_raw"><code class="name flex">
<span>def <span class="ident">open_raw</span></span>(<span>self,<br>filepath,<br>buffersize=10.0,<br>backsize=0.0,<br>verbose=0,<br>rate=44000,<br>channels=1,<br>encoding='FLOAT',<br>amax=1.0,<br>unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_raw(self, filepath, buffersize=10.0, backsize=0.0,
             verbose=0, rate=44000, channels=1, encoding=&#39;FLOAT&#39;,
             amax=1.0, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Load data from a raw file.

    Raw files just contain the data and absolutely no metadata, not
    even the smapling rate, number of channels, etc.
    Supported file formats are:

    - raw files (*.raw)
    - LabView scandata (*.scandat)

    Parameters
    ----------
    filepath: str or Path
        Path of the file to load.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    rate: float
        Sampling rate of the data in Hertz.
    channels: int
        Number of channels multiplexed in the data.
    encoding: str
        The encoding of the data stored in the file.
        Valid encodings are &#39;PCM_16&#39;, &#39;PCM_32&#39;, &#39;PCM_64&#39;, &#39;FLOAT&#39;, or
        &#39;DOUBLE&#39; or lower-case versions thereof.
    amax: float
        The amplitude range of the data.
    unit: str
        The unit of the data.
    &#34;&#34;&#34;
    encodings = {&#39;PCM_16&#39;: &#39;i2&#39;,
                 &#39;PCM_32&#39;: &#39;i4&#39;,
                 &#39;PCM_64&#39;: &#39;i8&#39;,
                 &#39;FLOAT&#39;: &#39;f&#39;,
                 &#39;DOUBLE&#39;: &#39;d&#39;}
    encoding = encoding.upper()
    if not encoding in encodings:
        raise ValueError(f&#39;invalid encoding {encoding} for raw file!&#39;)
    self.dtype = np.dtype(encodings[encoding])
    self.verbose = verbose
    self.filepath = Path(filepath)
    self.file_paths = [self.filepath]
    self.file_indices = [0]
    self.sf = open(self.filepath, &#39;rb&#39;)
    if self.verbose &gt; 0:
        print(f&#39;open_raw(&#34;{self.filepath}&#34;)&#39;)
    self.rate = float(rate)
    # file size:
    self.channels = int(channels)
    self.sf.seek(0, os.SEEK_END)
    self.frames = self.sf.tell()//self.dtype.itemsize//self.channels
    self.sf.seek(0)
    self.shape = (self.frames, self.channels)
    self.ndim = len(self.shape)
    self.size = self.frames*self.channels
    self.format = &#39;RAW&#39;
    self.encoding = self.numpy_encodings.get(self.dtype, &#39;UNKNOWN&#39;)
    self.unit = unit
    self.ampl_max = float(amax)
    self.ampl_min = -self.ampl_max
    self.offset = 0
    self.bufferframes = int(buffersize*self.rate)
    self.backframes = int(backsize*self.rate)
    self.init_buffer()
    self.close = self._close_raw
    self.load_audio_buffer = self._load_buffer_raw
    self._metadata = None
    self._load_metadata = None
    self._locs = None
    self._labels = None
    self._load_markers = None</code></pre>
</details>
<div class="desc"><p>Load data from a raw file.</p>
<p>Raw files just contain the data and absolutely no metadata, not
even the smapling rate, number of channels, etc.
Supported file formats are:</p>
<ul>
<li>raw files (*.raw)</li>
<li>LabView scandata (*.scandat)</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path of the file to load.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling rate of the data in Hertz.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of channels multiplexed in the data.</dd>
<dt><strong><code>encoding</code></strong> :&ensp;<code>str</code></dt>
<dd>The encoding of the data stored in the file.
Valid encodings are 'PCM_16', 'PCM_32', 'PCM_64', 'FLOAT', or
'DOUBLE' or lower-case versions thereof.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>The amplitude range of the data.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>The unit of the data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open_audioio"><code class="name flex">
<span>def <span class="ident">open_audioio</span></span>(<span>self,<br>filepath,<br>buffersize=10.0,<br>backsize=0.0,<br>verbose=0,<br>gainkey=['AIMaxVolt', 'gain'],<br>sep='.',<br>amax=None,<br>unit='a.u.')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_audioio(self, filepath, buffersize=10.0, backsize=0.0,
                 verbose=0, gainkey=default_gain_keys, sep=&#39;.&#39;,
                 amax=None, unit=&#39;a.u.&#39;):
    &#34;&#34;&#34;Open an audio file.

    See the [audioio](https://github.com/bendalab/audioio) package
    for details.

    Parameters
    ----------
    filepath: str
        Path to an audio file.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index
        in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    gainkey: str or list of str
        Key in the file&#39;s metadata that holds some gain information.
        If found, the data will be multiplied with the gain,
        and if available, the corresponding unit is returned.
        See the [audioio.get_gain()](https://bendalab.github.io/audioio/api/audiometadata.html#audioio.audiometadata.get_gain) function for details.
    sep: str
        String that separates section names in `gainkey`.
    amax: None or float
        If specified and no gain has been found in the metadata,
        then use this as the amplitude range.
    unit: None or str
        If specified and no gain has been found in the metadata,
        then this is the unit of the data.

    &#34;&#34;&#34;
    self.verbose = verbose
    super(DataLoader, self).open(filepath, buffersize, backsize, verbose)
    md = self.metadata()
    fac, unit = get_gain(md, gainkey, sep, amax, unit)
    if fac is None:
        self.gain_fac = 1.0 
    else:
        self.gain_fac = fac
        self._load_buffer_audio_org = self.load_audio_buffer
        self.load_audio_buffer = self._load_buffer_audioio
    self.ampl_min *= self.gain_fac
    self.ampl_max *= self.gain_fac
    self.unit = unit
    return self</code></pre>
</details>
<div class="desc"><p>Open an audio file.</p>
<p>See the <a href="https://github.com/bendalab/audioio">audioio</a> package
for details.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to an audio file.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index
in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>gainkey</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Key in the file's metadata that holds some gain information.
If found, the data will be multiplied with the gain,
and if available, the corresponding unit is returned.
See the <a href="https://bendalab.github.io/audioio/api/audiometadata.html#audioio.audiometadata.get_gain">audioio.get_gain()</a> function for details.</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>String that separates section names in <code>gainkey</code>.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>If specified and no gain has been found in the metadata,
then use this as the amplitude range.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>None</code> or <code>str</code></dt>
<dd>If specified and no gain has been found in the metadata,
then this is the unit of the data.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open_multiple"><code class="name flex">
<span>def <span class="ident">open_multiple</span></span>(<span>self,<br>filepaths,<br>buffersize=10.0,<br>backsize=0.0,<br>verbose=0,<br>mode='strict',<br>rate=None,<br>channels=None,<br>unit=None,<br>amax=None,<br>end_indices=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open_multiple(self, filepaths, buffersize=10.0, backsize=0.0,
                  verbose=0, mode=&#39;strict&#39;, rate=None, channels=None,
                  unit=None, amax=None, end_indices=None):
    &#34;&#34;&#34;Open multiple files as a single concatenated array.

    Parameters
    ----------
    filepaths: list of str or Path
        List of file paths of audio files.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index in seconds.
    verbose: int
        If larger than zero show detailed error/warning messages.
    mode: &#39;relaxed&#39; or &#39;strict&#39;
        If &#39;strict&#39;, only concatenate files if they contain
        a start time in their meta data.
    rate: float
        If provided, do a minimal initialization (no checking)
        using the provided sampling rate (in Hertz), channels,
        unit, maximum amplitude, and end_indices.
    channels: int
        If provided, do a minimal initialization (no checking)
        using the provided rate, number of channels,
        unit, maximum amplitude, and end_indices.
    unit: str
        If provided, do a minimal initialization (no checking)
        using the provided rate, number of channels,
        unit, maximum amplitude, and end_indices.
    amax: float
        If provided, do a minimal initialization (no checking)
        using the provided rate, number of channels,
        unit, maximum amplitude amax, and end_indices.
    end_indices: sequence of int
        If provided, do a minimal initialization (no checking)
        using the provided rate, channels,
        unit, maximum amplitude, and end_indices.

    Raises
    ------
    TypeError
        `filepaths` must be a sequence.
    ValueError
        Empty `filepaths`.
    FileNotFoundError
        `filepaths` does not contain a single valid file.

    &#34;&#34;&#34;
    if not isinstance(filepaths, (list, tuple, np.ndarray)):
        raise TypeError(&#39;input argument filepaths is not a sequence!&#39;)
    if len(filepaths) == 0:
        raise ValueError(&#39;input argument filepaths is empy sequence!&#39;)
    self.buffersize = buffersize
    self.backsize = backsize
    self.filepath = None
    self.file_paths = []
    self.open_files = []
    self.open_loaders = []
    self.data_files = []
    self.collect_counter = 0
    self.frames = 0
    self.start_indices = []
    self.end_indices = []
    self.start_time = None
    start_time = None
    self._metadata = {}
    self._locs = np.zeros((0, 2), dtype=int)
    self._labels = np.zeros((0, 2), dtype=object)
    if end_indices is not None:
        self.file_paths = [Path(fp) for fp in filepaths]
        self.filepath = self.file_paths[0]
        self.data_files = [None] * len(self.file_paths)
        self.frames = end_indices[-1]
        self.start_indices = [0] + list(end_indices[:-1])
        self.end_indices = end_indices
        self.format = None
        self.encoding = None
        self.rate = rate
        self.channels = channels
        self.unit = unit
        self.ampl_max = amax
        self.ampl_min = -amax
    else:
        for filepath in filepaths:
            try:
                a = DataLoader(filepath, buffersize, backsize, verbose)
            except Exception as e:
                if verbose &gt; 0:
                    print(e)
                continue
            # collect metadata:
            md = a.metadata()
            fmd = flatten_metadata(md, True)
            add_metadata(self._metadata, fmd)
            if self.filepath is None:
                # first file:
                self.filepath = a.filepath
                self.format = a.format
                self.encoding = a.encoding
                self.rate = a.rate
                self.channels = a.channels
                self.unit = a.unit
                self.ampl_max = a.ampl_max
                self.ampl_min = a.ampl_min
                self.start_time = get_datetime(md)
                start_time = self.start_time
                stime = self.start_time
            else:
                # check channels, rate, and amplitudes:
                error_str = None
                if a.channels != self.channels:
                    error_str = f&#39;number of channels differs: &#39; \
                                f&#39;{a.channels} in {a.filepath} versus &#39; \
                                f&#39;{self.channels} in {self.filepath}&#39;
                if a.rate != self.rate:
                    error_str = f&#39;sampling rates differ: &#39; \
                                f&#39;{a.rate} in {a.filepath} versus &#39; \
                                f&#39;{self.rate} in {self.filepath}&#39;
                if a.ampl_min != self.ampl_min:
                    error_str = f&#39;minimum amplitudes differ: &#39; \
                                f&#39;{a.ampl_min} in {a.filepath} versus &#39; \
                                f&#39;{self.ampl_min} in {self.filepath}&#39;
                if a.ampl_max != self.ampl_max:
                    error_Str = f&#39;maximum amplitudes differ: &#39; \
                                f&#39;{a.ampl_max} in {a.filepath} versus &#39; \
                                f&#39;{self.ampl_max} in {self.filepath}&#39;
                # check start time of recording:
                stime = get_datetime(md)
                if mode == &#39;strict&#39; and (start_time is None or stime is None):
                    error_str = &#39;file does not contain a start time in its meta data&#39;
                if start_time is not None and stime is not None and \
                   abs(start_time - stime) &gt; timedelta(seconds=self._max_time_diff):
                    error_str = f&#39;start time does not indicate continuous recording: &#39; \
                                f&#39;expected {start_time} instead of &#39; \
                                f&#39;{stime} in {a.filepath}&#39;
                if error_str is not None:
                    if verbose &gt; 0:
                        print(error_str)
                    a.close()
                    del a
                    break
            # markers:
            locs, labels = a.markers()
            locs[:,0] += self.frames
            self._locs = np.vstack((self._locs, locs))
            self._labels = np.vstack((self._labels, labels))
            # indices:
            self.start_indices.append(self.frames)
            self.frames += a.frames
            self.end_indices.append(self.frames)
            if stime is not None:
                start_time = stime + timedelta(seconds=a.frames/a.rate)
            # add file to lists:
            self.file_paths.append(a.filepath)
            if len(self.open_files) &lt; AudioLoader.max_open_files:
                self.open_files.append(a)
            else:
                a.close()
            if len(self.open_loaders) &lt; AudioLoader.max_open_loaders:
                self.data_files.append(a)
                self.open_loaders.append(a)
            else:
                a.close()
                del a
                self.data_files.append(None)
        if len(self.data_files) == 0:
            raise FileNotFoundError(&#39;input argument filepaths does not contain any valid audio file!&#39;)
        # set startime from first file:
        if self.start_time is not None:
            set_starttime(self._metadata, self.start_time)
    # setup infrastructure:
    self.file_indices = self.start_indices
    self.start_indices = np.array(self.start_indices)
    self.end_indices = np.array(self.end_indices)
    self.shape = (self.frames, self.channels)
    self.bufferframes = int(buffersize*self.rate)
    self.backframes = int(backsize*self.rate)
    self.init_buffer()
    self.close = self._close_multiple
    self.load_audio_buffer = self._load_buffer_multiple
    self._load_metadata = None
    self._load_markers = None
    return self</code></pre>
</details>
<div class="desc"><p>Open multiple files as a single concatenated array.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepaths</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>Path</code></dt>
<dd>List of file paths of audio files.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If larger than zero show detailed error/warning messages.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>'relaxed'</code> or <code>'strict'</code></dt>
<dd>If 'strict', only concatenate files if they contain
a start time in their meta data.</dd>
<dt><strong><code>rate</code></strong> :&ensp;<code>float</code></dt>
<dd>If provided, do a minimal initialization (no checking)
using the provided sampling rate (in Hertz), channels,
unit, maximum amplitude, and end_indices.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>int</code></dt>
<dd>If provided, do a minimal initialization (no checking)
using the provided rate, number of channels,
unit, maximum amplitude, and end_indices.</dd>
<dt><strong><code>unit</code></strong> :&ensp;<code>str</code></dt>
<dd>If provided, do a minimal initialization (no checking)
using the provided rate, number of channels,
unit, maximum amplitude, and end_indices.</dd>
<dt><strong><code>amax</code></strong> :&ensp;<code>float</code></dt>
<dd>If provided, do a minimal initialization (no checking)
using the provided rate, number of channels,
unit, maximum amplitude amax, and end_indices.</dd>
<dt><strong><code>end_indices</code></strong> :&ensp;<code>sequence</code> of <code>int</code></dt>
<dd>If provided, do a minimal initialization (no checking)
using the provided rate, channels,
unit, maximum amplitude, and end_indices.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd><code>filepaths</code> must be a sequence.</dd>
<dt><code>ValueError</code></dt>
<dd>Empty <code>filepaths</code>.</dd>
<dt><code>FileNotFoundError</code></dt>
<dd><code>filepaths</code> does not contain a single valid file.</dd>
</dl></div>
</dd>
<dt id="thunderlab.dataloader.DataLoader.open"><code class="name flex">
<span>def <span class="ident">open</span></span>(<span>self, filepath, buffersize=10.0, backsize=0.0, verbose=0, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open(self, filepath, buffersize=10.0, backsize=0.0,
         verbose=0, **kwargs):
    &#34;&#34;&#34;Open file with time-series data for reading.

    Parameters
    ----------
    filepath: str or list of str
        Name of the file or list of many file names that should be
        made accessible as a single array.
    buffersize: float
        Size of internal buffer in seconds.
    backsize: float
        Part of the buffer to be loaded before the requested start index
        in seconds.
    verbose: int
        If &gt; 0 show detailed error/warning messages.
    **kwargs: dict
        Further keyword arguments that are passed on to the 
        format specific opening functions.
        For example:
        - `amax`: the amplitude range of the data.
        - &#39;unit&#39;: the unit of the data.

    Raises
    ------
    ValueError:
        `filepath` is empty string.
    &#34;&#34;&#34;
    # list of implemented open functions:
    data_open_funcs = (
        (&#39;relacs&#39;, check_relacs, self.open_relacs, 1),
        (&#39;fishgrid&#39;, check_fishgrid, self.open_fishgrid, 1),
        (&#39;container&#39;, check_container, self.open_container, 1),
        (&#39;raw&#39;, check_raw, self.open_raw, 1),
        (&#39;audioio&#39;, None, self.open_audioio, 0),
        )
    
    self.buffer = np.array([])
    self.rate = 0.0
    if not filepath:
        raise ValueError(&#39;input argument filepath is empty string.&#39;)
    if isinstance(filepath, (list, tuple, np.ndarray)):
        if len(filepath) &gt; 1:
            self.open_multiple(filepath, buffersize, backsize,
                               verbose, **kwargs)
            if len(self.file_paths) &gt; 1:
                return self
            filepath = self.file_paths[0]
            self.close()
        else:
            filepath = filepath[0]
    # open data:
    for name, check_file, open_file, v in  data_open_funcs:
        if check_file is None or check_file(filepath):
            open_file(filepath, buffersize, backsize, verbose, **kwargs)
            if v*verbose &gt; 1:
                if self.format is not None:
                    print(f&#39;  format       : {self.format}&#39;)
                if self.encoding is not None:
                    print(f&#39;  encoding     : {self.encoding}&#39;)
                print(f&#39;  sampling rate: {self.rate} Hz&#39;)
                print(f&#39;  channels     : {self.channels}&#39;)
                print(f&#39;  frames       : {self.frames}&#39;)
                print(f&#39;  range        : {self.ampl_max:g}{self.unit}&#39;)
            break
    return self</code></pre>
</details>
<div class="desc"><p>Open file with time-series data for reading.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code></dt>
<dd>Name of the file or list of many file names that should be
made accessible as a single array.</dd>
<dt><strong><code>buffersize</code></strong> :&ensp;<code>float</code></dt>
<dd>Size of internal buffer in seconds.</dd>
<dt><strong><code>backsize</code></strong> :&ensp;<code>float</code></dt>
<dd>Part of the buffer to be loaded before the requested start index
in seconds.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>If &gt; 0 show detailed error/warning messages.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Further keyword arguments that are passed on to the
format specific opening functions.
For example:
- <code>amax</code>: the amplitude range of the data.
- 'unit': the unit of the data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="valueerror">Valueerror</h2>
<p><code>filepath</code> is empty string.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul>
<li><a href="#supported-file-formats">Supported file formats</a></li>
<li><a href="#metadata">Metadata</a></li>
<li><a href="#markers">Markers</a></li>
<li><a href="#aditional-format-specific-functions">Aditional, format specific functions</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="thunderlab" href="index.html">thunderlab</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="thunderlab.dataloader.data_loader_funcs" href="#thunderlab.dataloader.data_loader_funcs">data_loader_funcs</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="thunderlab.dataloader.relacs_samplerate_unit" href="#thunderlab.dataloader.relacs_samplerate_unit">relacs_samplerate_unit</a></code></li>
<li><code><a title="thunderlab.dataloader.relacs_header" href="#thunderlab.dataloader.relacs_header">relacs_header</a></code></li>
<li><code><a title="thunderlab.dataloader.check_relacs" href="#thunderlab.dataloader.check_relacs">check_relacs</a></code></li>
<li><code><a title="thunderlab.dataloader.relacs_trace_files" href="#thunderlab.dataloader.relacs_trace_files">relacs_trace_files</a></code></li>
<li><code><a title="thunderlab.dataloader.load_relacs" href="#thunderlab.dataloader.load_relacs">load_relacs</a></code></li>
<li><code><a title="thunderlab.dataloader.metadata_relacs" href="#thunderlab.dataloader.metadata_relacs">metadata_relacs</a></code></li>
<li><code><a title="thunderlab.dataloader.fishgrid_spacings" href="#thunderlab.dataloader.fishgrid_spacings">fishgrid_spacings</a></code></li>
<li><code><a title="thunderlab.dataloader.fishgrid_grids" href="#thunderlab.dataloader.fishgrid_grids">fishgrid_grids</a></code></li>
<li><code><a title="thunderlab.dataloader.check_fishgrid" href="#thunderlab.dataloader.check_fishgrid">check_fishgrid</a></code></li>
<li><code><a title="thunderlab.dataloader.fishgrid_trace_files" href="#thunderlab.dataloader.fishgrid_trace_files">fishgrid_trace_files</a></code></li>
<li><code><a title="thunderlab.dataloader.load_fishgrid" href="#thunderlab.dataloader.load_fishgrid">load_fishgrid</a></code></li>
<li><code><a title="thunderlab.dataloader.metadata_fishgrid" href="#thunderlab.dataloader.metadata_fishgrid">metadata_fishgrid</a></code></li>
<li><code><a title="thunderlab.dataloader.markers_fishgrid" href="#thunderlab.dataloader.markers_fishgrid">markers_fishgrid</a></code></li>
<li><code><a title="thunderlab.dataloader.check_container" href="#thunderlab.dataloader.check_container">check_container</a></code></li>
<li><code><a title="thunderlab.dataloader.extract_container_data" href="#thunderlab.dataloader.extract_container_data">extract_container_data</a></code></li>
<li><code><a title="thunderlab.dataloader.load_container" href="#thunderlab.dataloader.load_container">load_container</a></code></li>
<li><code><a title="thunderlab.dataloader.extract_container_metadata" href="#thunderlab.dataloader.extract_container_metadata">extract_container_metadata</a></code></li>
<li><code><a title="thunderlab.dataloader.metadata_container" href="#thunderlab.dataloader.metadata_container">metadata_container</a></code></li>
<li><code><a title="thunderlab.dataloader.extract_container_markers" href="#thunderlab.dataloader.extract_container_markers">extract_container_markers</a></code></li>
<li><code><a title="thunderlab.dataloader.markers_container" href="#thunderlab.dataloader.markers_container">markers_container</a></code></li>
<li><code><a title="thunderlab.dataloader.check_raw" href="#thunderlab.dataloader.check_raw">check_raw</a></code></li>
<li><code><a title="thunderlab.dataloader.load_raw" href="#thunderlab.dataloader.load_raw">load_raw</a></code></li>
<li><code><a title="thunderlab.dataloader.load_audioio" href="#thunderlab.dataloader.load_audioio">load_audioio</a></code></li>
<li><code><a title="thunderlab.dataloader.load_data" href="#thunderlab.dataloader.load_data">load_data</a></code></li>
<li><code><a title="thunderlab.dataloader.metadata" href="#thunderlab.dataloader.metadata">metadata</a></code></li>
<li><code><a title="thunderlab.dataloader.markers" href="#thunderlab.dataloader.markers">markers</a></code></li>
<li><code><a title="thunderlab.dataloader.demo" href="#thunderlab.dataloader.demo">demo</a></code></li>
<li><code><a title="thunderlab.dataloader.main" href="#thunderlab.dataloader.main">main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="thunderlab.dataloader.DataLoader" href="#thunderlab.dataloader.DataLoader">DataLoader</a></code></h4>
<ul class="two-column">
<li><code><a title="thunderlab.dataloader.DataLoader.open_relacs" href="#thunderlab.dataloader.DataLoader.open_relacs">open_relacs</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open_fishgrid" href="#thunderlab.dataloader.DataLoader.open_fishgrid">open_fishgrid</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open_container" href="#thunderlab.dataloader.DataLoader.open_container">open_container</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open_raw" href="#thunderlab.dataloader.DataLoader.open_raw">open_raw</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open_audioio" href="#thunderlab.dataloader.DataLoader.open_audioio">open_audioio</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open_multiple" href="#thunderlab.dataloader.DataLoader.open_multiple">open_multiple</a></code></li>
<li><code><a title="thunderlab.dataloader.DataLoader.open" href="#thunderlab.dataloader.DataLoader.open">open</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
